<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Zhang Yixue" />


<title>Model Selection</title>

<script src="site_libs/header-attrs/header-attrs.js"></script>
<script src="site_libs/jquery/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui/jquery-ui.min.js"></script>
<link href="site_libs/tocify/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify/jquery.tocify.js"></script>
<script src="site_libs/navigation/tabsets.js"></script>
<link href="site_libs/highlightjs/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs/highlight.js"></script>
<link href="site_libs/tile-view/tile-view.css" rel="stylesheet" />
<script src="site_libs/tile-view/tile-view.js"></script>
<script type="application/json" id="xaringanExtra-editable-docid">{"id":"x6343e671a5d4599837a630b065c716b","expires":1}</script>
<script src="site_libs/himalaya/himalaya.js"></script>
<script src="site_libs/js-cookie/js.cookie.js"></script>
<link href="site_libs/editable/editable.css" rel="stylesheet" />
<script src="site_libs/editable/editable.js"></script>
<script src="site_libs/fabric/fabric.min.js"></script>
<link href="site_libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
<script src="site_libs/xaringanExtra-scribble/scribble.js"></script>
<script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
<link href="site_libs/panelset/panelset.css" rel="stylesheet" />
<script src="site_libs/panelset/panelset.js"></script>
<script src="site_libs/xaringanExtra_fit-screen/fit-screen.js"></script>
<script src="site_libs/htmlwidgets/htmlwidgets.js"></script>
<link href="site_libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding/datatables.js"></script>
<link href="site_libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk/js/crosstalk.min.js"></script>
<link href="site_libs/font-awesome/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Tutorials</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/zhanglantian2021/Tutorials">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Model Selection</h1>
<h4 class="author">Zhang Yixue</h4>
<h4 class="date">June , 2022</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2022-07-08
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>Tutorials/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version 1.7.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20220708code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20220708)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20220708code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20220708)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomzhanglantian2021Tutorialstree0e2162577898694d35cacd0b4edf849f9d9940abtargetblank0e21625a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/zhanglantian2021/Tutorials/tree/0e2162577898694d35cacd0b4edf849f9d9940ab" target="_blank">0e21625</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomzhanglantian2021Tutorialstree0e2162577898694d35cacd0b4edf849f9d9940abtargetblank0e21625a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/zhanglantian2021/Tutorials/tree/0e2162577898694d35cacd0b4edf849f9d9940ab" target="_blank">0e21625</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    analysis/ReproScie-note_cache/

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were made to the R Markdown (<code>analysis/AdvanceSta-slides.rmd</code>) and HTML (<code>docs/AdvanceSta-slides.html</code>) files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/zhanglantian2021/Tutorials/blob/0e2162577898694d35cacd0b4edf849f9d9940ab/analysis/AdvanceSta-slides.rmd" target="_blank">0e21625</a>
</td>
<td>
zhanglantian2021
</td>
<td>
2022-07-08
</td>
<td>
first
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<style type="text/css">
<style type="text/css">
body, td {
   font-size: 20px;
}
code.r{
  font-size: 19px;
}
pre {
  font-size: 70px
}
</style>
</style>
<table style="width:6%;">
<colgroup>
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th>class: center, middle # Overcomplicated models # Oversimplified models ??? Since kyle’s course content is too much, so I just focus on one question to start my presentation ,In this process I will also talk generally about what is Generalized linear model and linear mixed model but there would not be too much details because of the litmiithed time. Anyway, the question is about when we try to Analysis our data, even we have built a model to explain the relationship between the response variables and independent variables, how could we know this model is good or not? Based this question, I rebuilt two kinds of situation, one is Overcomplicated models, another is Oversimplified models, in the fist case ,i would use the Generalized linear model as the example , in the second case i would use the linear mixed model as the example.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>class: center, middle # Overcomplicated models</td>
</tr>
</tbody>
</table>
<div id="example-1" class="section level2">
<h2>example 1</h2>
<div id="htmlwidget-01b15cddcdaaeffe8189" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-01b15cddcdaaeffe8189">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400"],["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","261","262","263","264","265","266","267","268","269","270","271","272","273","274","275","276","277","278","279","280","281","282","283","284","285","286","287","288","289","290","291","292","293","294","295","296","297","298","299","300","301","302","303","304","305","306","307","308","309","310","311","312","313","314","315","316","317","318","319","320","321","322","323","324","325","326","327","328","329","330","331","332","333","334","335","336","337","338","339","340","341","342","343","344","345","346","347","348","349","350","351","352","353","354","355","356","357","358","359","360","361","362","363","364","365","366","367","368","369","370","371","372","373","374","375","376","377","378","379","380","381","382","383","384","385","386","387","388","389","390","391","392","393","394","395","396","397","398","399","400"],[0,1,1,1,0,1,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0,1,0,0,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,1,0,1,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,1,0,1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,1,1,0,1,0,1,0,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,0,0,0,0,1,1,1,0,0,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,1,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,0,0,1,0,1,1,0,0,1,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0],[380,660,800,640,520,760,560,400,540,700,800,440,760,700,700,480,780,360,800,540,500,660,600,680,760,800,620,520,780,520,540,760,600,800,360,400,580,520,500,520,560,580,600,500,700,460,580,500,440,400,640,440,740,680,660,740,560,380,400,600,620,560,640,680,580,600,740,620,580,800,640,300,480,580,720,720,560,800,540,620,700,620,500,380,500,520,600,600,700,660,700,720,800,580,660,660,640,480,700,400,340,580,380,540,660,740,700,480,400,480,680,420,360,600,720,620,440,700,800,340,520,480,520,500,720,540,600,740,540,460,620,640,580,500,560,500,560,700,620,600,640,700,620,580,580,380,480,560,480,740,800,400,640,580,620,580,560,480,660,700,600,640,700,520,580,700,440,720,500,600,400,540,680,800,500,620,520,620,620,300,620,500,700,540,500,800,560,580,560,500,640,800,640,380,600,560,660,400,600,580,800,580,700,420,600,780,740,640,540,580,740,580,460,640,600,660,340,460,460,560,540,680,480,800,800,720,620,540,480,720,580,600,380,420,800,620,660,480,500,700,440,520,680,620,540,800,680,440,680,640,660,620,520,540,740,640,520,620,520,640,680,440,520,620,520,380,560,600,680,500,640,540,680,660,520,600,460,580,680,660,660,360,660,520,440,600,800,660,800,420,620,800,680,800,480,520,560,460,540,720,640,660,400,680,220,580,540,580,540,440,560,660,660,520,540,300,340,780,480,540,460,460,500,420,520,680,680,560,580,500,740,660,420,560,460,620,520,620,540,660,500,560,500,580,520,500,600,580,400,620,780,620,580,700,540,760,700,720,560,720,520,540,680,460,560,480,460,620,580,800,540,680,680,620,560,560,620,800,640,540,700,540,540,660,480,420,740,580,640,640,800,660,600,620,460,620,560,460,700,600],[3.61,3.67,4,3.19,2.93,3,2.98,3.08,3.39,3.92,4,3.22,4,3.08,4,3.44,3.87,2.56,3.75,3.81,3.17,3.63,2.82,3.19,3.35,3.66,3.61,3.74,3.22,3.29,3.78,3.35,3.4,4,3.14,3.05,3.25,2.9,3.13,2.68,2.42,3.32,3.15,3.31,2.94,3.45,3.46,2.97,2.48,3.35,3.86,3.13,3.37,3.27,3.34,4,3.19,2.94,3.65,2.82,3.18,3.32,3.67,3.85,4,3.59,3.62,3.3,3.69,3.73,4,2.92,3.39,4,3.45,4,3.36,4,3.12,4,2.9,3.07,2.71,2.91,3.6,2.98,3.32,3.48,3.28,4,3.83,3.64,3.9,2.93,3.44,3.33,3.52,3.57,2.88,3.31,3.15,3.57,3.33,3.94,3.95,2.97,3.56,3.13,2.93,3.45,3.08,3.41,3,3.22,3.84,3.99,3.45,3.72,3.7,2.92,3.74,2.67,2.85,2.98,3.88,3.38,3.54,3.74,3.19,3.15,3.17,2.79,3.4,3.08,2.95,3.57,3.33,4,3.4,3.58,3.93,3.52,3.94,3.4,3.4,3.43,3.4,2.71,2.91,3.31,3.74,3.38,3.94,3.46,3.69,2.86,2.52,3.58,3.49,3.82,3.13,3.5,3.56,2.73,3.3,4,3.24,3.77,4,3.62,3.51,2.81,3.48,3.43,3.53,3.37,2.62,3.23,3.33,3.01,3.78,3.88,4,3.84,2.79,3.6,3.61,2.88,3.07,3.35,2.94,3.54,3.76,3.59,3.47,3.59,3.07,3.23,3.63,3.77,3.31,3.2,4,3.92,3.89,3.8,3.54,3.63,3.16,3.5,3.34,3.02,2.87,3.38,3.56,2.91,2.9,3.64,2.98,3.59,3.28,3.99,3.02,3.47,2.9,3.5,3.58,3.02,3.43,3.42,3.29,3.28,3.38,2.67,3.53,3.05,3.49,4,2.86,3.45,2.76,3.81,2.96,3.22,3.04,3.91,3.34,3.17,3.64,3.73,3.31,3.21,4,3.55,3.52,3.35,3.3,3.95,3.51,3.81,3.11,3.15,3.19,3.95,3.9,3.34,3.24,3.64,3.46,2.81,3.95,3.33,3.67,3.32,3.12,2.98,3.77,3.58,3,3.14,3.94,3.27,3.45,3.1,3.39,3.31,3.22,3.7,3.15,2.26,3.45,2.78,3.7,3.97,2.55,3.25,3.16,3.07,3.5,3.4,3.3,3.6,3.15,3.98,2.83,3.46,3.17,3.51,3.13,2.98,4,3.67,3.77,3.65,3.46,2.84,3,3.63,3.71,3.28,3.14,3.58,3.01,2.69,2.7,3.9,3.31,3.48,3.34,2.93,4,3.59,2.96,3.43,3.64,3.71,3.15,3.09,3.2,3.47,3.23,2.65,3.95,3.06,3.35,3.03,3.35,3.8,3.36,2.85,4,3.43,3.12,3.52,3.78,2.81,3.27,3.31,3.69,3.94,4,3.49,3.14,3.44,3.36,2.78,2.93,3.63,4,3.89,3.77,3.76,2.42,3.37,3.78,3.49,3.63,4,3.12,2.7,3.65,3.49,3.51,4,2.62,3.02,3.86,3.36,3.17,3.51,3.05,3.88,3.38,3.75,3.99,4,3.04,2.63,3.65,3.89],[3,3,1,4,4,2,1,2,3,2,4,1,1,2,1,3,4,3,2,1,3,2,4,4,2,1,1,4,2,1,4,3,3,3,1,2,1,3,2,3,2,2,2,3,2,3,2,4,4,3,3,4,4,2,3,3,3,3,2,4,2,4,3,3,3,2,4,1,1,1,3,4,4,2,4,3,3,3,1,1,4,2,2,4,3,2,2,2,1,2,2,1,2,2,2,2,4,2,2,3,3,3,4,3,2,2,1,2,3,2,4,4,3,1,3,3,2,2,1,3,2,2,3,3,3,4,1,4,2,4,2,2,2,3,2,3,4,3,2,1,2,4,4,3,4,3,2,3,1,1,1,2,2,3,3,4,2,1,2,3,2,2,2,2,2,1,4,3,3,3,3,3,3,2,4,2,2,3,3,3,3,4,2,2,4,2,3,2,2,2,2,3,3,4,2,2,3,4,3,4,3,2,1,4,1,3,1,1,3,2,4,2,2,3,2,3,1,1,1,2,3,3,1,3,2,3,2,4,2,2,4,3,2,3,1,2,2,2,4,3,2,1,3,2,1,3,2,2,3,3,4,4,2,4,4,3,2,3,2,2,2,2,3,3,3,3,4,3,2,3,2,3,2,1,2,2,3,1,4,2,2,3,4,4,2,4,1,4,4,4,2,2,2,1,1,3,1,2,2,3,2,3,2,2,3,4,1,2,2,3,3,2,3,4,4,2,2,4,4,1,3,2,4,2,3,1,2,2,2,4,3,3,1,3,3,1,3,4,1,3,4,3,4,2,3,3,2,2,2,2,2,3,3,2,2,1,2,1,3,3,1,1,2,2,1,3,3,3,1,2,2,3,1,1,2,4,2,2,3,2,2,2,2,1,2,1,2,2,2,2,2,2,3,2,3,2,3,2,2,3]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>row.names<\/th>\n      <th>admit<\/th>\n      <th>gre<\/th>\n      <th>gpa<\/th>\n      <th>rank<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4,5]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>??? here is the example 1, the response variable is about Admission Qualifications, 1 means you got that ,0 means you faild, and here are 3 independent variables, gre is the grades of one kind of tests, and gpa is the average of all grades about the courses in your graduate school. rank is the the ranking of the school you are applying to. obviously, the response variable does not fit the normal distribution, and it is binomial data!! so we need to use the glm!! — ## Maximum Likelihood Estimation - MLE is the most likely value of the parameters given the data. - Deviance is difference between likelihoods and the saturated Lik .pull-left[ <img src="E:/academic_resources/note-tutorial/data/img/sta-slides1.png"
width="400" />]</p>
<p>.pull-right[ <img src="E:/academic_resources/note-tutorial/data/img/sta-slides2.png"
width="350" />]</p>
<p>??? - 左 before showing the code , I have to introduce what is Maximum Likelihood Estimation generally. Briefly MLE is the most likely value of the parameters given the data which means that we rebuit another function and put all the data and parameters in this new function, then we just need to find the turing point of this function, just like seeking the derivative. - 右 In addition to finding the parameters of glm, by this way, we also use this method to evaluate the fitted model, first we need to build the Null model which means minimal information explained and the formula looks like y ~ 1 (no predictors); then the Saturated model which means maximal information explained y~ b1x1 + b2x2 + x3 +….+ xn(one parameter for each data ); lastyly, the Fitted model is our prediction model,the fomular looks like:y ~ b1x1 + b2x2, we use this way to evaluate, I would explain more in the code</p>
<table style="width:6%;">
<colgroup>
<col width="5%" />
</colgroup>
<tbody>
<tr class="odd">
<td>.panelset[ .panel[.panel-name[Code-built]</td>
</tr>
<tr class="even">
<td><code>r mydata &lt;- read.csv("E:/academic_resources/note-tutorial/data/binary.csv",header=T,sep=" ") mydata$rank &lt;- as.factor(mydata$rank) #全模型 dim(mydata) mydata$x1 &lt;- as.factor(1:nrow(mydata)) glmS &lt;- glm(admit ~ x1, data = mydata, family = "binomial") #零模型 glm0 &lt;- glm(admit ~ 1, data = mydata, family = "binomial") #被测试模型1 glm1 &lt;- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial") #被测试模型2 glm2 &lt;- glm(admit ~ gpa+rank, data = mydata, family = "binomial")</code> ]</td>
</tr>
<tr class="odd">
<td>.panel[.panel-name[Code-compare]</td>
</tr>
<tr class="even">
<td>```r #Q1:glmS and glm0 ? summary(glmS)<span class="math inline">\(deviance summary(glm0)\)</span>deviance summary(glm1)$deviance 2<em>(logLik(glmS)-logLik(glm0)) 2</em>(logLik(glmS)-logLik(glm1)) summary(glm1)</td>
</tr>
<tr class="odd">
<td>#Q2:glm1 and glm2 ? summary(glm1)<span class="math inline">\(deviance summary(glm2)\)</span>deviance anova(glm1,glm2,test=‘Chisq’)</td>
</tr>
<tr class="even">
<td>#Q3:another way-AIC library(MuMIn) options(na.action = “na.fail”) dredge(glm1) print(AICglm1 &lt;- -2<em>(logLik(glm1))+ 2</em>6) print(AICglm2 &lt;- -2<em>(logLik(glm2))+ 2</em>5) ``` ]</td>
</tr>
<tr class="odd">
<td>.panel[.panel-name[Q1] .left-column[</td>
</tr>
<tr class="even">
<td><code>[1] 2.320633e-09</code></td>
</tr>
<tr class="odd">
<td><code>[1] 499.9765</code></td>
</tr>
<tr class="even">
<td><code>[1] 458.5175</code></td>
</tr>
<tr class="odd">
<td><code>'log Lik.' 499.9765 (df=400)</code></td>
</tr>
<tr class="even">
<td><code>'log Lik.' 458.5175 (df=400)</code> ]</td>
</tr>
<tr class="odd">
<td>.right-column[</td>
</tr>
<tr class="even">
<td><img src="E:/academic_resources/note-tutorial/data/img/sta-slides3.png"
width="800" /> ] ]</td>
</tr>
<tr class="odd">
<td>.panel[.panel-name[Q2]</td>
</tr>
<tr class="even">
<td><code>[1] 458.5175</code></td>
</tr>
<tr class="odd">
<td><code>[1] 462.8753</code></td>
</tr>
<tr class="even">
<td>``` Analysis of Deviance Table</td>
</tr>
<tr class="odd">
<td>Model 1: admit ~ gre + gpa + rank Model 2: admit ~ gpa + rank Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi) 1 394 458.52 2 395 462.88 -1 -4.3578 0.03684 *</td>
</tr>
</tbody>
</table>
<p>Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ’ ’ 1</p>
<pre><code>]



.panel[.panel-name[Q3]

</code></pre>
<p>‘log Lik.’ 470.5175 (df=6)</p>
<pre><code></code></pre>
<p>‘log Lik.’ 472.8753 (df=5)</p>
<pre><code></code></pre>
<p>Global model call: glm(formula = admit ~ gre + gpa + rank, family = “binomial”, data = mydata) — Model selection table (Intrc) gpa gre rank df logLik AICc delta weight 8 -3.9900 0.8040 0.002264 + 6 -229.259 470.7 0.00 0.686 6 -3.4640 1.0520 + 5 -231.438 473.0 2.30 0.218 7 -1.8020 0.003224 + 5 -232.266 474.7 3.95 0.095 5 0.1643 + 4 -237.483 483.1 12.34 0.001 4 -4.9490 0.7547 0.002691 3 -240.172 486.4 15.67 0.000 3 -2.9010 0.003582 2 -243.028 490.1 19.36 0.000 2 -4.3580 1.0510 2 -243.484 491.0 20.27 0.000 1 -0.7653 1 -249.988 502.0 31.26 0.000 Models ranked by AICc(x)</p>
<pre><code>]
]

???
- 1. first, we put our data into the matrix called mydata,  and because the rank is Categorical variable, so we set it as the factor. then,in order to buid the satured model we create a new vector we called x1 , and x1 is made of the number from 1 to 400 because there are 400 rows in the raw data, but i am not sure why buiding  the saturated model in this way, maybe  due to the assumption that consecutive natural numbers are perfectly normally distributed. second we build the null model, as you can see there is no predictor, and we build two fitted model, one includes three predictors anthoer includes 2 predictors , there is no reason why i remove the gre, doing this just for comparison and Explanation.
-2. Q1: 
    - as we said before, the deviance is the difference between the likelihood of model we intersted and the likelihhod of saturated, 
    - so the result of summary(glmS)$deviance should touch 0, because there is no differnce between the saturated model. 
    - and the result of summary(glm0)$deviance (499)should be the maximal because do you remeber the picture, the distance between the null model and the saturated model is the largest. we could see it from the result of summary function of any other fitted model(here!!!) 
    - and the result of summary(glm1)$deviance(458) is the difference between saturated model and glm1 model, we could see it in the summary result(here!!!!)
2. so the following two fomular just for showing how to caculte the deviance , their results should be the same as these two lines of code.lets see the result. 
-2. Q1:generally,  among the several fitted models,The smaller the residuals, the better the model!!! becase  when the deviance is smaller,it means our fitted model is closer to the saturated model, and the unexplained part of the response variation is less. so now we could see Q2
- C-c!!!!Q2：we use the code  like this to get these two fitted model to get their devicane , and see the result(Q2)!!!!! the first one is smaller, could we say  that the glm1 is better????? No!!!because we need to test the diffence bwteween these two model&#39;s deviance is significant or not !!! C-c!!!we use anova function, and specify the chi-squared distribution to test, Q2!!see the result ,it significant, so the first one is better!!!
- C-C!!!!should i write all fitted model like this way ？C-c？？no！we could use the function called dredge from the MUMIN package and we would get all subset models and AIC,AIC is an Indicator to help us to know which model is the best, and these two lines show how to calculate AIC, as you can see the likelihood also used here ,so the we should choose the smaller AIC, let&#39;s see the result Q3!!! 
- Q3!! the first row is the glm1， every preditors are included,the secon row is glm2, just remove the gre.
 


---
class: center, middle
# Oversimplified models
???
 let&#39;s see situation 2 
---
## example 2

```{=html}
&lt;div id=&quot;htmlwidget-5f4a463289f8d3751ae9&quot; style=&quot;width:100%;height:auto;&quot; class=&quot;datatables html-widget&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;application/json&quot; data-for=&quot;htmlwidget-5f4a463289f8d3751ae9&quot;&gt;{&quot;x&quot;:{&quot;filter&quot;:&quot;none&quot;,&quot;vertical&quot;:false,&quot;data&quot;:[[&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,&quot;7&quot;,&quot;8&quot;,&quot;9&quot;,&quot;10&quot;,&quot;11&quot;,&quot;12&quot;,&quot;13&quot;,&quot;14&quot;,&quot;15&quot;,&quot;16&quot;,&quot;17&quot;,&quot;18&quot;,&quot;19&quot;,&quot;20&quot;,&quot;21&quot;,&quot;22&quot;,&quot;23&quot;,&quot;24&quot;,&quot;25&quot;,&quot;26&quot;,&quot;27&quot;,&quot;28&quot;,&quot;29&quot;,&quot;30&quot;,&quot;31&quot;,&quot;32&quot;,&quot;33&quot;,&quot;34&quot;,&quot;35&quot;,&quot;36&quot;,&quot;37&quot;,&quot;38&quot;,&quot;39&quot;,&quot;40&quot;,&quot;41&quot;,&quot;42&quot;,&quot;43&quot;,&quot;44&quot;,&quot;45&quot;,&quot;46&quot;,&quot;47&quot;,&quot;48&quot;,&quot;49&quot;,&quot;50&quot;,&quot;51&quot;,&quot;52&quot;,&quot;53&quot;,&quot;54&quot;,&quot;55&quot;,&quot;56&quot;,&quot;57&quot;,&quot;58&quot;,&quot;59&quot;,&quot;60&quot;,&quot;61&quot;,&quot;62&quot;,&quot;63&quot;,&quot;64&quot;,&quot;65&quot;,&quot;66&quot;,&quot;67&quot;,&quot;68&quot;,&quot;69&quot;,&quot;70&quot;,&quot;71&quot;,&quot;72&quot;,&quot;73&quot;,&quot;74&quot;,&quot;75&quot;,&quot;76&quot;,&quot;77&quot;,&quot;78&quot;,&quot;79&quot;,&quot;80&quot;,&quot;81&quot;,&quot;82&quot;,&quot;83&quot;,&quot;84&quot;,&quot;85&quot;,&quot;86&quot;,&quot;87&quot;,&quot;88&quot;,&quot;89&quot;,&quot;90&quot;,&quot;91&quot;,&quot;92&quot;,&quot;93&quot;,&quot;94&quot;,&quot;95&quot;,&quot;96&quot;,&quot;97&quot;,&quot;98&quot;,&quot;99&quot;,&quot;100&quot;,&quot;101&quot;,&quot;102&quot;,&quot;103&quot;,&quot;104&quot;,&quot;105&quot;,&quot;106&quot;,&quot;107&quot;,&quot;108&quot;,&quot;109&quot;,&quot;110&quot;,&quot;111&quot;,&quot;112&quot;,&quot;113&quot;,&quot;114&quot;,&quot;115&quot;,&quot;116&quot;,&quot;117&quot;,&quot;118&quot;,&quot;119&quot;,&quot;120&quot;,&quot;121&quot;,&quot;122&quot;,&quot;123&quot;,&quot;124&quot;,&quot;125&quot;,&quot;126&quot;,&quot;127&quot;,&quot;128&quot;,&quot;129&quot;,&quot;130&quot;,&quot;131&quot;,&quot;132&quot;,&quot;133&quot;,&quot;134&quot;,&quot;135&quot;,&quot;136&quot;,&quot;137&quot;,&quot;138&quot;,&quot;139&quot;,&quot;140&quot;,&quot;141&quot;,&quot;142&quot;,&quot;143&quot;,&quot;144&quot;,&quot;145&quot;,&quot;146&quot;,&quot;147&quot;,&quot;148&quot;,&quot;149&quot;,&quot;150&quot;,&quot;151&quot;,&quot;152&quot;,&quot;153&quot;,&quot;154&quot;,&quot;155&quot;,&quot;156&quot;,&quot;157&quot;,&quot;158&quot;,&quot;159&quot;,&quot;160&quot;,&quot;161&quot;,&quot;162&quot;,&quot;163&quot;,&quot;164&quot;,&quot;165&quot;,&quot;166&quot;,&quot;167&quot;,&quot;168&quot;,&quot;169&quot;,&quot;170&quot;,&quot;171&quot;,&quot;172&quot;,&quot;173&quot;,&quot;174&quot;,&quot;175&quot;,&quot;176&quot;,&quot;177&quot;,&quot;178&quot;,&quot;179&quot;,&quot;180&quot;,&quot;181&quot;,&quot;182&quot;,&quot;183&quot;,&quot;184&quot;,&quot;185&quot;,&quot;186&quot;,&quot;187&quot;,&quot;188&quot;,&quot;189&quot;,&quot;190&quot;,&quot;191&quot;,&quot;192&quot;,&quot;193&quot;,&quot;194&quot;,&quot;195&quot;,&quot;196&quot;,&quot;197&quot;,&quot;198&quot;,&quot;199&quot;,&quot;200&quot;,&quot;201&quot;,&quot;202&quot;,&quot;203&quot;,&quot;204&quot;,&quot;205&quot;,&quot;206&quot;,&quot;207&quot;,&quot;208&quot;,&quot;209&quot;,&quot;210&quot;,&quot;211&quot;,&quot;212&quot;,&quot;213&quot;,&quot;214&quot;,&quot;215&quot;,&quot;216&quot;,&quot;217&quot;,&quot;218&quot;,&quot;219&quot;,&quot;220&quot;,&quot;221&quot;,&quot;222&quot;,&quot;223&quot;,&quot;224&quot;,&quot;225&quot;,&quot;226&quot;,&quot;227&quot;,&quot;228&quot;,&quot;229&quot;,&quot;230&quot;,&quot;231&quot;,&quot;232&quot;,&quot;233&quot;,&quot;234&quot;,&quot;235&quot;,&quot;236&quot;,&quot;237&quot;,&quot;238&quot;,&quot;239&quot;,&quot;240&quot;,&quot;241&quot;,&quot;242&quot;,&quot;243&quot;,&quot;244&quot;,&quot;245&quot;,&quot;246&quot;,&quot;247&quot;,&quot;248&quot;,&quot;249&quot;,&quot;250&quot;,&quot;251&quot;,&quot;252&quot;,&quot;253&quot;,&quot;254&quot;,&quot;255&quot;,&quot;256&quot;,&quot;257&quot;,&quot;258&quot;,&quot;259&quot;,&quot;260&quot;,&quot;261&quot;,&quot;262&quot;,&quot;263&quot;,&quot;264&quot;,&quot;265&quot;,&quot;266&quot;,&quot;267&quot;,&quot;268&quot;,&quot;269&quot;,&quot;270&quot;,&quot;271&quot;,&quot;272&quot;,&quot;273&quot;,&quot;274&quot;,&quot;275&quot;,&quot;276&quot;,&quot;277&quot;,&quot;278&quot;,&quot;279&quot;,&quot;280&quot;,&quot;281&quot;,&quot;282&quot;,&quot;283&quot;,&quot;284&quot;,&quot;285&quot;,&quot;286&quot;,&quot;287&quot;,&quot;288&quot;,&quot;289&quot;,&quot;290&quot;,&quot;291&quot;,&quot;292&quot;,&quot;293&quot;,&quot;294&quot;,&quot;295&quot;,&quot;296&quot;,&quot;297&quot;,&quot;298&quot;,&quot;299&quot;,&quot;300&quot;,&quot;301&quot;,&quot;302&quot;,&quot;303&quot;,&quot;304&quot;,&quot;305&quot;,&quot;306&quot;,&quot;307&quot;,&quot;308&quot;,&quot;309&quot;,&quot;310&quot;,&quot;311&quot;,&quot;312&quot;,&quot;313&quot;,&quot;314&quot;,&quot;315&quot;,&quot;316&quot;,&quot;317&quot;,&quot;318&quot;,&quot;319&quot;,&quot;320&quot;,&quot;321&quot;,&quot;322&quot;,&quot;323&quot;,&quot;324&quot;,&quot;325&quot;,&quot;326&quot;,&quot;327&quot;,&quot;328&quot;,&quot;329&quot;,&quot;330&quot;,&quot;331&quot;,&quot;332&quot;,&quot;333&quot;,&quot;334&quot;,&quot;335&quot;,&quot;336&quot;,&quot;337&quot;,&quot;338&quot;,&quot;339&quot;,&quot;340&quot;,&quot;341&quot;,&quot;342&quot;,&quot;343&quot;,&quot;344&quot;,&quot;345&quot;,&quot;346&quot;,&quot;347&quot;,&quot;348&quot;,&quot;349&quot;,&quot;350&quot;,&quot;351&quot;,&quot;352&quot;,&quot;353&quot;,&quot;354&quot;,&quot;355&quot;,&quot;356&quot;,&quot;357&quot;,&quot;358&quot;,&quot;359&quot;,&quot;360&quot;,&quot;361&quot;,&quot;362&quot;,&quot;363&quot;,&quot;364&quot;,&quot;365&quot;,&quot;366&quot;,&quot;367&quot;,&quot;368&quot;,&quot;369&quot;,&quot;370&quot;,&quot;371&quot;,&quot;372&quot;,&quot;373&quot;,&quot;374&quot;,&quot;375&quot;,&quot;376&quot;,&quot;377&quot;,&quot;378&quot;,&quot;379&quot;,&quot;380&quot;,&quot;381&quot;,&quot;382&quot;,&quot;383&quot;,&quot;384&quot;,&quot;385&quot;,&quot;386&quot;,&quot;387&quot;,&quot;388&quot;,&quot;389&quot;,&quot;390&quot;,&quot;391&quot;,&quot;392&quot;,&quot;393&quot;,&quot;394&quot;,&quot;395&quot;,&quot;396&quot;,&quot;397&quot;,&quot;398&quot;,&quot;399&quot;,&quot;400&quot;,&quot;401&quot;,&quot;402&quot;,&quot;403&quot;,&quot;404&quot;,&quot;405&quot;,&quot;406&quot;,&quot;407&quot;,&quot;408&quot;,&quot;409&quot;,&quot;410&quot;,&quot;411&quot;,&quot;412&quot;,&quot;413&quot;,&quot;414&quot;,&quot;415&quot;,&quot;416&quot;,&quot;417&quot;,&quot;418&quot;,&quot;419&quot;,&quot;420&quot;,&quot;421&quot;,&quot;422&quot;,&quot;423&quot;,&quot;424&quot;,&quot;425&quot;,&quot;426&quot;,&quot;427&quot;,&quot;428&quot;,&quot;429&quot;,&quot;430&quot;,&quot;431&quot;,&quot;432&quot;,&quot;433&quot;,&quot;434&quot;,&quot;435&quot;,&quot;436&quot;,&quot;437&quot;,&quot;438&quot;,&quot;439&quot;,&quot;440&quot;,&quot;441&quot;,&quot;442&quot;,&quot;443&quot;,&quot;444&quot;,&quot;445&quot;,&quot;446&quot;,&quot;447&quot;,&quot;448&quot;,&quot;449&quot;,&quot;450&quot;,&quot;451&quot;,&quot;452&quot;,&quot;453&quot;,&quot;454&quot;,&quot;455&quot;,&quot;456&quot;,&quot;457&quot;,&quot;458&quot;,&quot;459&quot;,&quot;460&quot;,&quot;461&quot;,&quot;462&quot;,&quot;463&quot;,&quot;464&quot;,&quot;465&quot;,&quot;466&quot;,&quot;467&quot;,&quot;468&quot;,&quot;469&quot;,&quot;470&quot;,&quot;471&quot;,&quot;472&quot;,&quot;473&quot;,&quot;474&quot;,&quot;475&quot;,&quot;476&quot;,&quot;477&quot;,&quot;478&quot;,&quot;479&quot;,&quot;480&quot;,&quot;481&quot;,&quot;482&quot;,&quot;483&quot;,&quot;484&quot;,&quot;485&quot;,&quot;486&quot;,&quot;487&quot;,&quot;488&quot;,&quot;489&quot;,&quot;490&quot;,&quot;491&quot;,&quot;492&quot;,&quot;493&quot;,&quot;494&quot;,&quot;495&quot;,&quot;496&quot;,&quot;497&quot;,&quot;498&quot;,&quot;499&quot;,&quot;500&quot;,&quot;501&quot;,&quot;502&quot;,&quot;503&quot;,&quot;504&quot;,&quot;505&quot;,&quot;506&quot;,&quot;507&quot;,&quot;508&quot;,&quot;509&quot;,&quot;510&quot;,&quot;511&quot;,&quot;512&quot;,&quot;513&quot;,&quot;514&quot;,&quot;515&quot;,&quot;516&quot;,&quot;517&quot;,&quot;518&quot;,&quot;519&quot;,&quot;520&quot;,&quot;521&quot;,&quot;522&quot;,&quot;523&quot;,&quot;524&quot;,&quot;525&quot;,&quot;526&quot;,&quot;527&quot;,&quot;528&quot;,&quot;529&quot;,&quot;530&quot;,&quot;531&quot;,&quot;532&quot;,&quot;533&quot;,&quot;534&quot;,&quot;535&quot;,&quot;536&quot;,&quot;537&quot;,&quot;538&quot;,&quot;539&quot;,&quot;540&quot;,&quot;541&quot;,&quot;542&quot;,&quot;543&quot;,&quot;544&quot;,&quot;545&quot;,&quot;546&quot;,&quot;547&quot;,&quot;548&quot;,&quot;549&quot;,&quot;550&quot;,&quot;551&quot;,&quot;552&quot;,&quot;553&quot;,&quot;554&quot;,&quot;555&quot;,&quot;556&quot;,&quot;557&quot;,&quot;558&quot;,&quot;559&quot;,&quot;560&quot;,&quot;561&quot;,&quot;562&quot;,&quot;563&quot;,&quot;564&quot;,&quot;565&quot;,&quot;566&quot;,&quot;567&quot;,&quot;568&quot;,&quot;569&quot;,&quot;570&quot;,&quot;571&quot;,&quot;572&quot;,&quot;573&quot;,&quot;574&quot;,&quot;575&quot;,&quot;576&quot;,&quot;577&quot;,&quot;578&quot;,&quot;579&quot;,&quot;580&quot;,&quot;581&quot;,&quot;582&quot;,&quot;583&quot;,&quot;584&quot;,&quot;585&quot;,&quot;586&quot;,&quot;587&quot;,&quot;588&quot;,&quot;589&quot;,&quot;590&quot;,&quot;591&quot;,&quot;592&quot;,&quot;593&quot;,&quot;594&quot;,&quot;595&quot;,&quot;596&quot;,&quot;597&quot;,&quot;598&quot;,&quot;599&quot;,&quot;600&quot;,&quot;601&quot;,&quot;602&quot;,&quot;603&quot;,&quot;604&quot;,&quot;605&quot;,&quot;606&quot;,&quot;607&quot;,&quot;608&quot;,&quot;609&quot;,&quot;610&quot;,&quot;611&quot;,&quot;612&quot;,&quot;613&quot;,&quot;614&quot;,&quot;615&quot;,&quot;616&quot;,&quot;617&quot;,&quot;618&quot;,&quot;619&quot;,&quot;620&quot;,&quot;621&quot;,&quot;622&quot;,&quot;623&quot;,&quot;624&quot;,&quot;625&quot;,&quot;626&quot;,&quot;627&quot;,&quot;628&quot;,&quot;629&quot;,&quot;630&quot;,&quot;631&quot;,&quot;632&quot;,&quot;633&quot;,&quot;634&quot;,&quot;635&quot;,&quot;636&quot;,&quot;637&quot;,&quot;638&quot;,&quot;639&quot;,&quot;640&quot;,&quot;641&quot;,&quot;642&quot;,&quot;643&quot;,&quot;644&quot;,&quot;645&quot;,&quot;646&quot;,&quot;647&quot;,&quot;648&quot;,&quot;649&quot;,&quot;650&quot;,&quot;651&quot;,&quot;652&quot;,&quot;653&quot;,&quot;654&quot;,&quot;655&quot;,&quot;656&quot;,&quot;657&quot;,&quot;658&quot;,&quot;659&quot;,&quot;660&quot;,&quot;661&quot;,&quot;662&quot;,&quot;663&quot;,&quot;664&quot;,&quot;665&quot;,&quot;666&quot;,&quot;667&quot;,&quot;668&quot;,&quot;669&quot;,&quot;670&quot;,&quot;671&quot;,&quot;672&quot;,&quot;673&quot;,&quot;674&quot;,&quot;675&quot;,&quot;676&quot;,&quot;677&quot;,&quot;678&quot;,&quot;679&quot;,&quot;680&quot;,&quot;681&quot;,&quot;682&quot;,&quot;683&quot;,&quot;684&quot;,&quot;685&quot;,&quot;686&quot;,&quot;687&quot;,&quot;688&quot;,&quot;689&quot;,&quot;690&quot;,&quot;691&quot;,&quot;692&quot;,&quot;693&quot;,&quot;694&quot;,&quot;695&quot;,&quot;696&quot;,&quot;697&quot;,&quot;698&quot;,&quot;699&quot;,&quot;700&quot;,&quot;701&quot;,&quot;702&quot;,&quot;703&quot;,&quot;704&quot;,&quot;705&quot;,&quot;706&quot;,&quot;707&quot;,&quot;708&quot;,&quot;709&quot;,&quot;710&quot;,&quot;711&quot;,&quot;712&quot;,&quot;713&quot;,&quot;714&quot;,&quot;715&quot;,&quot;716&quot;,&quot;717&quot;,&quot;718&quot;,&quot;719&quot;,&quot;720&quot;,&quot;721&quot;,&quot;722&quot;,&quot;723&quot;,&quot;724&quot;,&quot;725&quot;,&quot;726&quot;,&quot;727&quot;,&quot;728&quot;,&quot;729&quot;,&quot;730&quot;,&quot;731&quot;,&quot;732&quot;,&quot;733&quot;,&quot;734&quot;,&quot;735&quot;,&quot;736&quot;,&quot;737&quot;,&quot;738&quot;,&quot;739&quot;,&quot;740&quot;,&quot;741&quot;,&quot;742&quot;,&quot;743&quot;,&quot;744&quot;,&quot;745&quot;,&quot;746&quot;,&quot;747&quot;,&quot;748&quot;,&quot;749&quot;,&quot;750&quot;,&quot;751&quot;,&quot;752&quot;,&quot;753&quot;,&quot;754&quot;,&quot;755&quot;,&quot;756&quot;,&quot;757&quot;,&quot;758&quot;,&quot;759&quot;,&quot;760&quot;,&quot;761&quot;,&quot;762&quot;,&quot;763&quot;,&quot;764&quot;,&quot;765&quot;,&quot;766&quot;,&quot;767&quot;,&quot;768&quot;,&quot;769&quot;,&quot;770&quot;,&quot;771&quot;,&quot;772&quot;,&quot;773&quot;,&quot;774&quot;,&quot;775&quot;,&quot;776&quot;,&quot;777&quot;,&quot;778&quot;,&quot;779&quot;,&quot;780&quot;,&quot;781&quot;,&quot;782&quot;,&quot;783&quot;,&quot;784&quot;,&quot;785&quot;,&quot;786&quot;,&quot;787&quot;,&quot;788&quot;,&quot;789&quot;,&quot;790&quot;,&quot;791&quot;,&quot;792&quot;,&quot;793&quot;,&quot;794&quot;,&quot;795&quot;,&quot;796&quot;,&quot;797&quot;,&quot;798&quot;,&quot;799&quot;,&quot;800&quot;,&quot;801&quot;,&quot;802&quot;,&quot;803&quot;,&quot;804&quot;,&quot;805&quot;,&quot;806&quot;,&quot;807&quot;,&quot;808&quot;,&quot;809&quot;,&quot;810&quot;,&quot;811&quot;,&quot;812&quot;,&quot;813&quot;,&quot;814&quot;,&quot;815&quot;,&quot;816&quot;,&quot;817&quot;,&quot;818&quot;,&quot;819&quot;,&quot;820&quot;,&quot;821&quot;,&quot;822&quot;,&quot;823&quot;,&quot;824&quot;,&quot;825&quot;,&quot;826&quot;,&quot;827&quot;,&quot;828&quot;,&quot;829&quot;,&quot;830&quot;,&quot;831&quot;,&quot;832&quot;,&quot;833&quot;,&quot;834&quot;,&quot;835&quot;,&quot;836&quot;,&quot;837&quot;,&quot;838&quot;,&quot;839&quot;,&quot;840&quot;,&quot;841&quot;,&quot;842&quot;,&quot;843&quot;,&quot;844&quot;,&quot;845&quot;,&quot;846&quot;,&quot;847&quot;,&quot;848&quot;,&quot;849&quot;,&quot;850&quot;,&quot;851&quot;,&quot;852&quot;,&quot;853&quot;,&quot;854&quot;,&quot;855&quot;,&quot;856&quot;,&quot;857&quot;,&quot;858&quot;,&quot;859&quot;,&quot;860&quot;,&quot;861&quot;,&quot;862&quot;,&quot;863&quot;,&quot;864&quot;,&quot;865&quot;,&quot;866&quot;,&quot;867&quot;,&quot;868&quot;,&quot;869&quot;,&quot;870&quot;,&quot;871&quot;,&quot;872&quot;,&quot;873&quot;,&quot;874&quot;,&quot;875&quot;,&quot;876&quot;,&quot;877&quot;,&quot;878&quot;,&quot;879&quot;,&quot;880&quot;,&quot;881&quot;,&quot;882&quot;,&quot;883&quot;,&quot;884&quot;,&quot;885&quot;,&quot;886&quot;,&quot;887&quot;,&quot;888&quot;,&quot;889&quot;,&quot;890&quot;,&quot;891&quot;,&quot;892&quot;,&quot;893&quot;,&quot;894&quot;,&quot;895&quot;,&quot;896&quot;,&quot;897&quot;,&quot;898&quot;,&quot;899&quot;,&quot;900&quot;,&quot;901&quot;,&quot;902&quot;,&quot;903&quot;,&quot;904&quot;,&quot;905&quot;,&quot;906&quot;,&quot;907&quot;,&quot;908&quot;,&quot;909&quot;,&quot;910&quot;,&quot;911&quot;,&quot;912&quot;,&quot;913&quot;,&quot;914&quot;,&quot;915&quot;,&quot;916&quot;,&quot;917&quot;,&quot;918&quot;,&quot;919&quot;,&quot;920&quot;,&quot;921&quot;,&quot;922&quot;,&quot;923&quot;,&quot;924&quot;,&quot;925&quot;,&quot;926&quot;,&quot;927&quot;,&quot;928&quot;,&quot;929&quot;,&quot;930&quot;,&quot;931&quot;,&quot;932&quot;,&quot;933&quot;,&quot;934&quot;,&quot;935&quot;,&quot;936&quot;,&quot;937&quot;,&quot;938&quot;,&quot;939&quot;,&quot;940&quot;,&quot;941&quot;,&quot;942&quot;,&quot;943&quot;,&quot;944&quot;,&quot;945&quot;,&quot;946&quot;,&quot;947&quot;,&quot;948&quot;,&quot;949&quot;,&quot;950&quot;,&quot;951&quot;,&quot;952&quot;,&quot;953&quot;,&quot;954&quot;,&quot;955&quot;,&quot;956&quot;,&quot;957&quot;,&quot;958&quot;,&quot;959&quot;,&quot;960&quot;,&quot;961&quot;,&quot;962&quot;,&quot;963&quot;,&quot;964&quot;,&quot;965&quot;,&quot;966&quot;,&quot;967&quot;,&quot;968&quot;,&quot;969&quot;,&quot;970&quot;,&quot;971&quot;,&quot;972&quot;,&quot;973&quot;,&quot;974&quot;,&quot;975&quot;,&quot;976&quot;,&quot;977&quot;,&quot;978&quot;,&quot;979&quot;,&quot;980&quot;,&quot;981&quot;,&quot;982&quot;,&quot;983&quot;,&quot;984&quot;,&quot;985&quot;,&quot;986&quot;,&quot;987&quot;,&quot;988&quot;,&quot;989&quot;,&quot;990&quot;,&quot;991&quot;,&quot;992&quot;,&quot;993&quot;,&quot;994&quot;,&quot;995&quot;,&quot;996&quot;,&quot;997&quot;,&quot;998&quot;,&quot;999&quot;,&quot;1000&quot;,&quot;1001&quot;,&quot;1002&quot;,&quot;1003&quot;,&quot;1004&quot;,&quot;1005&quot;,&quot;1006&quot;,&quot;1007&quot;,&quot;1008&quot;,&quot;1009&quot;,&quot;1010&quot;,&quot;1011&quot;,&quot;1012&quot;,&quot;1013&quot;,&quot;1014&quot;,&quot;1015&quot;,&quot;1016&quot;,&quot;1017&quot;,&quot;1018&quot;,&quot;1019&quot;,&quot;1020&quot;,&quot;1021&quot;,&quot;1022&quot;,&quot;1023&quot;,&quot;1024&quot;,&quot;1025&quot;,&quot;1026&quot;,&quot;1027&quot;,&quot;1028&quot;,&quot;1029&quot;,&quot;1030&quot;,&quot;1031&quot;,&quot;1032&quot;,&quot;1033&quot;,&quot;1034&quot;,&quot;1035&quot;,&quot;1036&quot;,&quot;1037&quot;,&quot;1038&quot;,&quot;1039&quot;,&quot;1040&quot;,&quot;1041&quot;,&quot;1042&quot;,&quot;1043&quot;,&quot;1044&quot;,&quot;1045&quot;,&quot;1046&quot;,&quot;1047&quot;,&quot;1048&quot;,&quot;1049&quot;,&quot;1050&quot;,&quot;1051&quot;,&quot;1052&quot;,&quot;1053&quot;,&quot;1054&quot;,&quot;1055&quot;,&quot;1056&quot;,&quot;1057&quot;,&quot;1058&quot;,&quot;1059&quot;,&quot;1060&quot;,&quot;1061&quot;,&quot;1062&quot;,&quot;1063&quot;,&quot;1064&quot;,&quot;1065&quot;,&quot;1066&quot;,&quot;1067&quot;,&quot;1068&quot;,&quot;1069&quot;,&quot;1070&quot;,&quot;1071&quot;,&quot;1072&quot;,&quot;1073&quot;,&quot;1074&quot;,&quot;1075&quot;,&quot;1076&quot;,&quot;1077&quot;,&quot;1078&quot;,&quot;1079&quot;,&quot;1080&quot;,&quot;1081&quot;,&quot;1082&quot;,&quot;1083&quot;,&quot;1084&quot;,&quot;1085&quot;,&quot;1086&quot;,&quot;1087&quot;,&quot;1088&quot;,&quot;1089&quot;,&quot;1090&quot;,&quot;1091&quot;,&quot;1092&quot;,&quot;1093&quot;,&quot;1094&quot;,&quot;1095&quot;,&quot;1096&quot;,&quot;1097&quot;,&quot;1098&quot;,&quot;1099&quot;,&quot;1100&quot;,&quot;1101&quot;,&quot;1102&quot;,&quot;1103&quot;,&quot;1104&quot;,&quot;1105&quot;,&quot;1106&quot;,&quot;1107&quot;,&quot;1108&quot;,&quot;1109&quot;,&quot;1110&quot;,&quot;1111&quot;,&quot;1112&quot;,&quot;1113&quot;,&quot;1114&quot;,&quot;1115&quot;,&quot;1116&quot;,&quot;1117&quot;,&quot;1118&quot;,&quot;1119&quot;,&quot;1120&quot;,&quot;1121&quot;,&quot;1122&quot;,&quot;1123&quot;,&quot;1124&quot;,&quot;1125&quot;,&quot;1126&quot;,&quot;1127&quot;,&quot;1128&quot;,&quot;1129&quot;,&quot;1130&quot;,&quot;1131&quot;,&quot;1132&quot;,&quot;1133&quot;,&quot;1134&quot;,&quot;1135&quot;,&quot;1136&quot;,&quot;1137&quot;,&quot;1138&quot;,&quot;1139&quot;,&quot;1140&quot;,&quot;1141&quot;,&quot;1142&quot;,&quot;1143&quot;,&quot;1144&quot;,&quot;1145&quot;,&quot;1146&quot;,&quot;1147&quot;,&quot;1148&quot;,&quot;1149&quot;,&quot;1150&quot;,&quot;1151&quot;,&quot;1152&quot;,&quot;1153&quot;,&quot;1154&quot;,&quot;1155&quot;,&quot;1156&quot;,&quot;1157&quot;,&quot;1158&quot;,&quot;1159&quot;,&quot;1160&quot;,&quot;1161&quot;,&quot;1162&quot;,&quot;1163&quot;,&quot;1164&quot;,&quot;1165&quot;,&quot;1166&quot;,&quot;1167&quot;,&quot;1168&quot;,&quot;1169&quot;,&quot;1170&quot;,&quot;1171&quot;,&quot;1172&quot;,&quot;1173&quot;,&quot;1174&quot;,&quot;1175&quot;,&quot;1176&quot;,&quot;1177&quot;,&quot;1178&quot;,&quot;1179&quot;,&quot;1180&quot;,&quot;1181&quot;,&quot;1182&quot;,&quot;1183&quot;,&quot;1184&quot;,&quot;1185&quot;,&quot;1186&quot;,&quot;1187&quot;,&quot;1188&quot;,&quot;1189&quot;,&quot;1190&quot;,&quot;1191&quot;,&quot;1192&quot;,&quot;1193&quot;,&quot;1194&quot;,&quot;1195&quot;,&quot;1196&quot;,&quot;1197&quot;,&quot;1198&quot;,&quot;1199&quot;,&quot;1200&quot;,&quot;1201&quot;,&quot;1202&quot;,&quot;1203&quot;,&quot;1204&quot;,&quot;1205&quot;,&quot;1206&quot;,&quot;1207&quot;,&quot;1208&quot;,&quot;1209&quot;,&quot;1210&quot;,&quot;1211&quot;,&quot;1212&quot;,&quot;1213&quot;,&quot;1214&quot;,&quot;1215&quot;,&quot;1216&quot;,&quot;1217&quot;,&quot;1218&quot;,&quot;1219&quot;,&quot;1220&quot;,&quot;1221&quot;,&quot;1222&quot;,&quot;1223&quot;,&quot;1224&quot;,&quot;1225&quot;,&quot;1226&quot;,&quot;1227&quot;,&quot;1228&quot;,&quot;1229&quot;,&quot;1230&quot;,&quot;1231&quot;,&quot;1232&quot;,&quot;1233&quot;,&quot;1234&quot;,&quot;1235&quot;,&quot;1236&quot;,&quot;1237&quot;,&quot;1238&quot;,&quot;1239&quot;,&quot;1240&quot;,&quot;1241&quot;,&quot;1242&quot;,&quot;1243&quot;,&quot;1244&quot;,&quot;1245&quot;,&quot;1246&quot;,&quot;1247&quot;,&quot;1248&quot;,&quot;1249&quot;,&quot;1250&quot;,&quot;1251&quot;,&quot;1252&quot;,&quot;1253&quot;,&quot;1254&quot;,&quot;1255&quot;,&quot;1256&quot;,&quot;1257&quot;,&quot;1258&quot;,&quot;1259&quot;,&quot;1260&quot;,&quot;1261&quot;,&quot;1262&quot;,&quot;1263&quot;,&quot;1264&quot;,&quot;1265&quot;,&quot;1266&quot;,&quot;1267&quot;,&quot;1268&quot;,&quot;1269&quot;,&quot;1270&quot;,&quot;1271&quot;,&quot;1272&quot;,&quot;1273&quot;,&quot;1274&quot;,&quot;1275&quot;,&quot;1276&quot;,&quot;1277&quot;,&quot;1278&quot;,&quot;1279&quot;,&quot;1280&quot;,&quot;1281&quot;,&quot;1282&quot;,&quot;1283&quot;,&quot;1284&quot;,&quot;1285&quot;,&quot;1286&quot;,&quot;1287&quot;,&quot;1288&quot;,&quot;1289&quot;,&quot;1290&quot;,&quot;1291&quot;,&quot;1292&quot;,&quot;1293&quot;,&quot;1294&quot;,&quot;1295&quot;,&quot;1296&quot;,&quot;1297&quot;,&quot;1298&quot;,&quot;1299&quot;,&quot;1300&quot;,&quot;1301&quot;,&quot;1302&quot;,&quot;1303&quot;,&quot;1304&quot;,&quot;1305&quot;,&quot;1306&quot;,&quot;1307&quot;,&quot;1308&quot;,&quot;1309&quot;,&quot;1310&quot;,&quot;1311&quot;,&quot;1312&quot;,&quot;1313&quot;,&quot;1314&quot;,&quot;1315&quot;,&quot;1316&quot;,&quot;1317&quot;,&quot;1318&quot;,&quot;1319&quot;,&quot;1320&quot;,&quot;1321&quot;,&quot;1322&quot;,&quot;1323&quot;,&quot;1324&quot;,&quot;1325&quot;,&quot;1326&quot;,&quot;1327&quot;,&quot;1328&quot;,&quot;1329&quot;,&quot;1330&quot;,&quot;1331&quot;,&quot;1332&quot;,&quot;1333&quot;,&quot;1334&quot;,&quot;1335&quot;,&quot;1336&quot;,&quot;1337&quot;,&quot;1338&quot;,&quot;1339&quot;,&quot;1340&quot;,&quot;1341&quot;,&quot;1342&quot;,&quot;1343&quot;,&quot;1344&quot;,&quot;1345&quot;,&quot;1346&quot;,&quot;1347&quot;,&quot;1348&quot;,&quot;1349&quot;,&quot;1350&quot;,&quot;1351&quot;,&quot;1352&quot;,&quot;1353&quot;,&quot;1354&quot;,&quot;1355&quot;,&quot;1356&quot;,&quot;1357&quot;,&quot;1358&quot;,&quot;1359&quot;,&quot;1360&quot;,&quot;1361&quot;,&quot;1362&quot;,&quot;1363&quot;,&quot;1364&quot;,&quot;1365&quot;,&quot;1366&quot;,&quot;1367&quot;,&quot;1368&quot;,&quot;1369&quot;,&quot;1370&quot;,&quot;1371&quot;,&quot;1372&quot;,&quot;1373&quot;,&quot;1374&quot;,&quot;1375&quot;,&quot;1376&quot;,&quot;1377&quot;,&quot;1378&quot;,&quot;1379&quot;,&quot;1380&quot;,&quot;1381&quot;,&quot;1382&quot;,&quot;1383&quot;,&quot;1384&quot;,&quot;1385&quot;,&quot;1386&quot;,&quot;1387&quot;,&quot;1388&quot;,&quot;1389&quot;,&quot;1390&quot;,&quot;1391&quot;,&quot;1392&quot;,&quot;1393&quot;,&quot;1394&quot;,&quot;1395&quot;,&quot;1396&quot;,&quot;1397&quot;,&quot;1398&quot;,&quot;1399&quot;,&quot;1400&quot;,&quot;1401&quot;,&quot;1402&quot;,&quot;1403&quot;,&quot;1404&quot;,&quot;1405&quot;,&quot;1406&quot;,&quot;1407&quot;,&quot;1408&quot;,&quot;1409&quot;,&quot;1410&quot;,&quot;1411&quot;,&quot;1412&quot;,&quot;1413&quot;,&quot;1414&quot;,&quot;1415&quot;,&quot;1416&quot;,&quot;1417&quot;,&quot;1418&quot;,&quot;1419&quot;,&quot;1420&quot;,&quot;1421&quot;,&quot;1422&quot;,&quot;1423&quot;,&quot;1424&quot;,&quot;1425&quot;,&quot;1426&quot;,&quot;1427&quot;,&quot;1428&quot;,&quot;1429&quot;,&quot;1430&quot;,&quot;1431&quot;,&quot;1432&quot;,&quot;1433&quot;,&quot;1434&quot;,&quot;1435&quot;,&quot;1436&quot;,&quot;1437&quot;,&quot;1438&quot;,&quot;1439&quot;,&quot;1440&quot;,&quot;1441&quot;,&quot;1442&quot;,&quot;1443&quot;,&quot;1444&quot;,&quot;1445&quot;,&quot;1446&quot;,&quot;1447&quot;,&quot;1448&quot;,&quot;1449&quot;,&quot;1450&quot;,&quot;1451&quot;,&quot;1452&quot;,&quot;1453&quot;,&quot;1454&quot;,&quot;1455&quot;,&quot;1456&quot;,&quot;1457&quot;,&quot;1458&quot;,&quot;1459&quot;,&quot;1460&quot;,&quot;1461&quot;,&quot;1462&quot;,&quot;1463&quot;,&quot;1464&quot;,&quot;1465&quot;,&quot;1466&quot;,&quot;1467&quot;,&quot;1468&quot;,&quot;1469&quot;,&quot;1470&quot;,&quot;1471&quot;,&quot;1472&quot;,&quot;1473&quot;,&quot;1474&quot;,&quot;1475&quot;,&quot;1476&quot;,&quot;1477&quot;,&quot;1478&quot;,&quot;1479&quot;,&quot;1480&quot;,&quot;1481&quot;,&quot;1482&quot;,&quot;1483&quot;,&quot;1484&quot;,&quot;1485&quot;,&quot;1486&quot;,&quot;1487&quot;,&quot;1488&quot;,&quot;1489&quot;,&quot;1490&quot;,&quot;1491&quot;,&quot;1492&quot;,&quot;1493&quot;,&quot;1494&quot;,&quot;1495&quot;,&quot;1496&quot;,&quot;1497&quot;,&quot;1498&quot;,&quot;1499&quot;,&quot;1500&quot;,&quot;1501&quot;,&quot;1502&quot;,&quot;1503&quot;,&quot;1504&quot;,&quot;1505&quot;,&quot;1506&quot;,&quot;1507&quot;,&quot;1508&quot;,&quot;1509&quot;,&quot;1510&quot;,&quot;1511&quot;,&quot;1512&quot;,&quot;1513&quot;,&quot;1514&quot;,&quot;1515&quot;,&quot;1516&quot;,&quot;1517&quot;,&quot;1518&quot;,&quot;1519&quot;,&quot;1520&quot;,&quot;1521&quot;,&quot;1522&quot;,&quot;1523&quot;,&quot;1524&quot;,&quot;1525&quot;,&quot;1526&quot;,&quot;1527&quot;,&quot;1528&quot;,&quot;1529&quot;,&quot;1530&quot;,&quot;1531&quot;,&quot;1532&quot;,&quot;1533&quot;,&quot;1534&quot;,&quot;1535&quot;,&quot;1536&quot;,&quot;1537&quot;,&quot;1538&quot;,&quot;1539&quot;,&quot;1540&quot;,&quot;1541&quot;,&quot;1542&quot;,&quot;1543&quot;,&quot;1544&quot;,&quot;1545&quot;,&quot;1546&quot;,&quot;1547&quot;,&quot;1548&quot;,&quot;1549&quot;,&quot;1550&quot;,&quot;1551&quot;,&quot;1552&quot;,&quot;1553&quot;,&quot;1554&quot;,&quot;1555&quot;,&quot;1556&quot;,&quot;1557&quot;,&quot;1558&quot;,&quot;1559&quot;,&quot;1560&quot;,&quot;1561&quot;,&quot;1562&quot;,&quot;1563&quot;,&quot;1564&quot;,&quot;1565&quot;,&quot;1566&quot;,&quot;1567&quot;,&quot;1568&quot;,&quot;1569&quot;,&quot;1570&quot;,&quot;1571&quot;,&quot;1572&quot;,&quot;1573&quot;,&quot;1574&quot;,&quot;1575&quot;,&quot;1576&quot;,&quot;1577&quot;,&quot;1578&quot;,&quot;1579&quot;,&quot;1580&quot;,&quot;1581&quot;,&quot;1582&quot;,&quot;1583&quot;,&quot;1584&quot;,&quot;1585&quot;,&quot;1586&quot;,&quot;1587&quot;,&quot;1588&quot;,&quot;1589&quot;,&quot;1590&quot;,&quot;1591&quot;,&quot;1592&quot;,&quot;1593&quot;,&quot;1594&quot;,&quot;1595&quot;,&quot;1596&quot;,&quot;1597&quot;,&quot;1598&quot;,&quot;1599&quot;,&quot;1600&quot;,&quot;1601&quot;,&quot;1602&quot;,&quot;1603&quot;,&quot;1604&quot;,&quot;1605&quot;,&quot;1606&quot;,&quot;1607&quot;,&quot;1608&quot;,&quot;1609&quot;,&quot;1610&quot;,&quot;1611&quot;,&quot;1612&quot;,&quot;1613&quot;,&quot;1614&quot;,&quot;1615&quot;,&quot;1616&quot;,&quot;1617&quot;,&quot;1618&quot;,&quot;1619&quot;,&quot;1620&quot;,&quot;1621&quot;,&quot;1622&quot;,&quot;1623&quot;,&quot;1624&quot;,&quot;1625&quot;,&quot;1626&quot;,&quot;1627&quot;,&quot;1628&quot;,&quot;1629&quot;,&quot;1630&quot;,&quot;1631&quot;,&quot;1632&quot;,&quot;1633&quot;,&quot;1634&quot;,&quot;1635&quot;,&quot;1636&quot;,&quot;1637&quot;,&quot;1638&quot;,&quot;1639&quot;,&quot;1640&quot;,&quot;1641&quot;,&quot;1642&quot;,&quot;1643&quot;,&quot;1644&quot;,&quot;1645&quot;,&quot;1646&quot;,&quot;1647&quot;,&quot;1648&quot;,&quot;1649&quot;,&quot;1650&quot;,&quot;1651&quot;,&quot;1652&quot;,&quot;1653&quot;,&quot;1654&quot;,&quot;1655&quot;,&quot;1656&quot;,&quot;1657&quot;,&quot;1658&quot;,&quot;1659&quot;,&quot;1660&quot;,&quot;1661&quot;,&quot;1662&quot;,&quot;1663&quot;,&quot;1664&quot;,&quot;1665&quot;,&quot;1666&quot;,&quot;1667&quot;,&quot;1668&quot;,&quot;1669&quot;,&quot;1670&quot;,&quot;1671&quot;,&quot;1672&quot;,&quot;1673&quot;,&quot;1674&quot;,&quot;1675&quot;,&quot;1676&quot;,&quot;1677&quot;,&quot;1678&quot;,&quot;1679&quot;,&quot;1680&quot;,&quot;1681&quot;,&quot;1682&quot;,&quot;1683&quot;,&quot;1684&quot;,&quot;1685&quot;,&quot;1686&quot;,&quot;1687&quot;,&quot;1688&quot;,&quot;1689&quot;,&quot;1690&quot;,&quot;1691&quot;,&quot;1692&quot;,&quot;1693&quot;,&quot;1694&quot;,&quot;1695&quot;,&quot;1696&quot;,&quot;1697&quot;,&quot;1698&quot;,&quot;1699&quot;,&quot;1700&quot;,&quot;1701&quot;,&quot;1702&quot;,&quot;1703&quot;,&quot;1704&quot;,&quot;1705&quot;,&quot;1706&quot;,&quot;1707&quot;,&quot;1708&quot;,&quot;1709&quot;,&quot;1710&quot;,&quot;1711&quot;,&quot;1712&quot;,&quot;1713&quot;,&quot;1714&quot;,&quot;1715&quot;,&quot;1716&quot;,&quot;1717&quot;,&quot;1718&quot;,&quot;1719&quot;,&quot;1720&quot;,&quot;1721&quot;,&quot;1722&quot;,&quot;1723&quot;,&quot;1724&quot;,&quot;1725&quot;,&quot;1726&quot;,&quot;1727&quot;,&quot;1728&quot;,&quot;1729&quot;,&quot;1730&quot;,&quot;1731&quot;,&quot;1732&quot;,&quot;1733&quot;,&quot;1734&quot;,&quot;1735&quot;,&quot;1736&quot;,&quot;1737&quot;,&quot;1738&quot;,&quot;1739&quot;,&quot;1740&quot;,&quot;1741&quot;,&quot;1742&quot;,&quot;1743&quot;,&quot;1744&quot;,&quot;1745&quot;,&quot;1746&quot;,&quot;1747&quot;,&quot;1748&quot;,&quot;1749&quot;,&quot;1750&quot;,&quot;1751&quot;,&quot;1752&quot;,&quot;1753&quot;,&quot;1754&quot;,&quot;1755&quot;,&quot;1756&quot;,&quot;1757&quot;,&quot;1758&quot;,&quot;1759&quot;,&quot;1760&quot;,&quot;1761&quot;,&quot;1762&quot;,&quot;1763&quot;,&quot;1764&quot;,&quot;1765&quot;,&quot;1766&quot;,&quot;1767&quot;,&quot;1768&quot;,&quot;1769&quot;,&quot;1770&quot;,&quot;1771&quot;,&quot;1772&quot;,&quot;1773&quot;,&quot;1774&quot;,&quot;1775&quot;,&quot;1776&quot;,&quot;1777&quot;,&quot;1778&quot;,&quot;1779&quot;,&quot;1780&quot;,&quot;1781&quot;,&quot;1782&quot;,&quot;1783&quot;,&quot;1784&quot;,&quot;1785&quot;,&quot;1786&quot;,&quot;1787&quot;,&quot;1788&quot;,&quot;1789&quot;,&quot;1790&quot;,&quot;1791&quot;,&quot;1792&quot;,&quot;1793&quot;,&quot;1794&quot;,&quot;1795&quot;,&quot;1796&quot;,&quot;1797&quot;,&quot;1798&quot;,&quot;1799&quot;,&quot;1800&quot;,&quot;1801&quot;,&quot;1802&quot;,&quot;1803&quot;,&quot;1804&quot;,&quot;1805&quot;,&quot;1806&quot;,&quot;1807&quot;,&quot;1808&quot;,&quot;1809&quot;,&quot;1810&quot;,&quot;1811&quot;,&quot;1812&quot;,&quot;1813&quot;,&quot;1814&quot;,&quot;1815&quot;,&quot;1816&quot;,&quot;1817&quot;,&quot;1818&quot;,&quot;1819&quot;,&quot;1820&quot;,&quot;1821&quot;,&quot;1822&quot;,&quot;1823&quot;,&quot;1824&quot;,&quot;1825&quot;,&quot;1826&quot;,&quot;1827&quot;,&quot;1828&quot;,&quot;1829&quot;,&quot;1830&quot;,&quot;1831&quot;,&quot;1832&quot;,&quot;1833&quot;,&quot;1834&quot;,&quot;1835&quot;,&quot;1836&quot;,&quot;1837&quot;,&quot;1838&quot;,&quot;1839&quot;,&quot;1840&quot;,&quot;1841&quot;,&quot;1842&quot;,&quot;1843&quot;,&quot;1844&quot;,&quot;1845&quot;,&quot;1846&quot;,&quot;1847&quot;,&quot;1848&quot;,&quot;1849&quot;,&quot;1850&quot;,&quot;1851&quot;,&quot;1852&quot;,&quot;1853&quot;,&quot;1854&quot;,&quot;1855&quot;,&quot;1856&quot;,&quot;1857&quot;,&quot;1858&quot;,&quot;1859&quot;,&quot;1860&quot;,&quot;1861&quot;,&quot;1862&quot;,&quot;1863&quot;,&quot;1864&quot;,&quot;1865&quot;,&quot;1866&quot;,&quot;1867&quot;,&quot;1868&quot;,&quot;1869&quot;,&quot;1870&quot;,&quot;1871&quot;,&quot;1872&quot;,&quot;1873&quot;,&quot;1874&quot;,&quot;1875&quot;,&quot;1876&quot;,&quot;1877&quot;,&quot;1878&quot;,&quot;1879&quot;,&quot;1880&quot;,&quot;1881&quot;,&quot;1882&quot;,&quot;1883&quot;,&quot;1884&quot;,&quot;1885&quot;,&quot;1886&quot;,&quot;1887&quot;,&quot;1888&quot;,&quot;1889&quot;,&quot;1890&quot;,&quot;1891&quot;,&quot;1892&quot;,&quot;1893&quot;,&quot;1894&quot;,&quot;1895&quot;,&quot;1896&quot;,&quot;1897&quot;,&quot;1898&quot;,&quot;1899&quot;,&quot;1900&quot;,&quot;1901&quot;,&quot;1902&quot;,&quot;1903&quot;,&quot;1904&quot;,&quot;1905&quot;,&quot;1906&quot;,&quot;1907&quot;,&quot;1908&quot;,&quot;1909&quot;,&quot;1910&quot;,&quot;1911&quot;,&quot;1912&quot;,&quot;1913&quot;,&quot;1914&quot;,&quot;1915&quot;,&quot;1916&quot;,&quot;1917&quot;,&quot;1918&quot;,&quot;1919&quot;,&quot;1920&quot;,&quot;1921&quot;,&quot;1922&quot;,&quot;1923&quot;,&quot;1924&quot;,&quot;1925&quot;,&quot;1926&quot;,&quot;1927&quot;,&quot;1928&quot;,&quot;1929&quot;,&quot;1930&quot;,&quot;1931&quot;,&quot;1932&quot;,&quot;1933&quot;,&quot;1934&quot;,&quot;1935&quot;,&quot;1936&quot;,&quot;1937&quot;,&quot;1938&quot;,&quot;1939&quot;,&quot;1940&quot;,&quot;1941&quot;,&quot;1942&quot;,&quot;1943&quot;,&quot;1944&quot;,&quot;1945&quot;,&quot;1946&quot;,&quot;1947&quot;,&quot;1948&quot;,&quot;1949&quot;,&quot;1950&quot;,&quot;1951&quot;,&quot;1952&quot;,&quot;1953&quot;,&quot;1954&quot;,&quot;1955&quot;,&quot;1956&quot;,&quot;1957&quot;,&quot;1958&quot;,&quot;1959&quot;,&quot;1960&quot;,&quot;1961&quot;,&quot;1962&quot;,&quot;1963&quot;,&quot;1964&quot;,&quot;1965&quot;,&quot;1966&quot;,&quot;1967&quot;,&quot;1968&quot;,&quot;1969&quot;,&quot;1970&quot;,&quot;1971&quot;,&quot;1972&quot;,&quot;1973&quot;,&quot;1974&quot;,&quot;1975&quot;,&quot;1976&quot;,&quot;1977&quot;,&quot;1978&quot;,&quot;1979&quot;,&quot;1980&quot;,&quot;1981&quot;,&quot;1982&quot;,&quot;1983&quot;,&quot;1984&quot;,&quot;1985&quot;,&quot;1986&quot;,&quot;1987&quot;,&quot;1988&quot;,&quot;1989&quot;,&quot;1990&quot;,&quot;1991&quot;,&quot;1992&quot;,&quot;1993&quot;,&quot;1994&quot;,&quot;1995&quot;,&quot;1996&quot;,&quot;1997&quot;,&quot;1998&quot;,&quot;1999&quot;,&quot;2000&quot;,&quot;2001&quot;,&quot;2002&quot;,&quot;2003&quot;,&quot;2004&quot;,&quot;2005&quot;,&quot;2006&quot;,&quot;2007&quot;,&quot;2008&quot;,&quot;2009&quot;,&quot;2010&quot;,&quot;2011&quot;,&quot;2012&quot;,&quot;2013&quot;,&quot;2014&quot;,&quot;2015&quot;,&quot;2016&quot;,&quot;2017&quot;,&quot;2018&quot;,&quot;2019&quot;,&quot;2020&quot;,&quot;2021&quot;,&quot;2022&quot;,&quot;2023&quot;,&quot;2024&quot;,&quot;2025&quot;,&quot;2026&quot;,&quot;2027&quot;,&quot;2028&quot;,&quot;2029&quot;,&quot;2030&quot;,&quot;2031&quot;,&quot;2032&quot;,&quot;2033&quot;,&quot;2034&quot;,&quot;2035&quot;,&quot;2036&quot;,&quot;2037&quot;,&quot;2038&quot;,&quot;2039&quot;,&quot;2040&quot;,&quot;2041&quot;,&quot;2042&quot;,&quot;2043&quot;,&quot;2044&quot;,&quot;2045&quot;,&quot;2046&quot;,&quot;2047&quot;,&quot;2048&quot;,&quot;2049&quot;,&quot;2050&quot;,&quot;2051&quot;,&quot;2052&quot;,&quot;2053&quot;,&quot;2054&quot;,&quot;2055&quot;,&quot;2056&quot;,&quot;2057&quot;,&quot;2058&quot;,&quot;2059&quot;,&quot;2060&quot;,&quot;2061&quot;,&quot;2062&quot;,&quot;2063&quot;,&quot;2064&quot;,&quot;2065&quot;,&quot;2066&quot;,&quot;2067&quot;,&quot;2068&quot;,&quot;2069&quot;,&quot;2070&quot;,&quot;2071&quot;,&quot;2072&quot;,&quot;2073&quot;,&quot;2074&quot;,&quot;2075&quot;,&quot;2076&quot;,&quot;2077&quot;,&quot;2078&quot;,&quot;2079&quot;,&quot;2080&quot;,&quot;2081&quot;,&quot;2082&quot;,&quot;2083&quot;,&quot;2084&quot;,&quot;2085&quot;,&quot;2086&quot;,&quot;2087&quot;,&quot;2088&quot;,&quot;2089&quot;,&quot;2090&quot;,&quot;2091&quot;,&quot;2092&quot;,&quot;2093&quot;,&quot;2094&quot;,&quot;2095&quot;,&quot;2096&quot;,&quot;2097&quot;,&quot;2098&quot;,&quot;2099&quot;,&quot;2100&quot;,&quot;2101&quot;,&quot;2102&quot;,&quot;2103&quot;,&quot;2104&quot;,&quot;2105&quot;,&quot;2106&quot;,&quot;2107&quot;,&quot;2108&quot;,&quot;2109&quot;,&quot;2110&quot;,&quot;2111&quot;,&quot;2112&quot;,&quot;2113&quot;,&quot;2114&quot;,&quot;2115&quot;,&quot;2116&quot;,&quot;2117&quot;,&quot;2118&quot;,&quot;2119&quot;,&quot;2120&quot;,&quot;2121&quot;,&quot;2122&quot;,&quot;2123&quot;,&quot;2124&quot;,&quot;2125&quot;,&quot;2126&quot;,&quot;2127&quot;,&quot;2128&quot;,&quot;2129&quot;,&quot;2130&quot;,&quot;2131&quot;,&quot;2132&quot;,&quot;2133&quot;,&quot;2134&quot;,&quot;2135&quot;,&quot;2136&quot;,&quot;2137&quot;,&quot;2138&quot;,&quot;2139&quot;,&quot;2140&quot;,&quot;2141&quot;,&quot;2142&quot;,&quot;2143&quot;,&quot;2144&quot;,&quot;2145&quot;,&quot;2146&quot;,&quot;2147&quot;,&quot;2148&quot;,&quot;2149&quot;,&quot;2150&quot;,&quot;2151&quot;,&quot;2152&quot;,&quot;2153&quot;,&quot;2154&quot;,&quot;2155&quot;,&quot;2156&quot;,&quot;2157&quot;,&quot;2158&quot;,&quot;2159&quot;,&quot;2160&quot;,&quot;2161&quot;,&quot;2162&quot;,&quot;2163&quot;,&quot;2164&quot;,&quot;2165&quot;,&quot;2166&quot;,&quot;2167&quot;,&quot;2168&quot;,&quot;2169&quot;,&quot;2170&quot;,&quot;2171&quot;,&quot;2172&quot;,&quot;2173&quot;,&quot;2174&quot;,&quot;2175&quot;,&quot;2176&quot;,&quot;2177&quot;,&quot;2178&quot;,&quot;2179&quot;,&quot;2180&quot;,&quot;2181&quot;,&quot;2182&quot;,&quot;2183&quot;,&quot;2184&quot;,&quot;2185&quot;,&quot;2186&quot;,&quot;2187&quot;,&quot;2188&quot;,&quot;2189&quot;,&quot;2190&quot;,&quot;2191&quot;,&quot;2192&quot;,&quot;2193&quot;,&quot;2194&quot;,&quot;2195&quot;,&quot;2196&quot;,&quot;2197&quot;,&quot;2198&quot;,&quot;2199&quot;,&quot;2200&quot;,&quot;2201&quot;,&quot;2202&quot;,&quot;2203&quot;,&quot;2204&quot;,&quot;2205&quot;,&quot;2206&quot;,&quot;2207&quot;,&quot;2208&quot;,&quot;2209&quot;,&quot;2210&quot;,&quot;2211&quot;,&quot;2212&quot;,&quot;2213&quot;,&quot;2214&quot;,&quot;2215&quot;,&quot;2216&quot;,&quot;2217&quot;,&quot;2218&quot;,&quot;2219&quot;,&quot;2220&quot;,&quot;2221&quot;,&quot;2222&quot;,&quot;2223&quot;,&quot;2224&quot;,&quot;2225&quot;,&quot;2226&quot;,&quot;2227&quot;,&quot;2228&quot;,&quot;2229&quot;,&quot;2230&quot;,&quot;2231&quot;,&quot;2232&quot;,&quot;2233&quot;,&quot;2234&quot;,&quot;2235&quot;,&quot;2236&quot;,&quot;2237&quot;,&quot;2238&quot;,&quot;2239&quot;,&quot;2240&quot;,&quot;2241&quot;,&quot;2242&quot;,&quot;2243&quot;,&quot;2244&quot;,&quot;2245&quot;,&quot;2246&quot;,&quot;2247&quot;,&quot;2248&quot;,&quot;2249&quot;,&quot;2250&quot;,&quot;2251&quot;,&quot;2252&quot;,&quot;2253&quot;,&quot;2254&quot;,&quot;2255&quot;,&quot;2256&quot;,&quot;2257&quot;,&quot;2258&quot;,&quot;2259&quot;,&quot;2260&quot;,&quot;2261&quot;,&quot;2262&quot;,&quot;2263&quot;,&quot;2264&quot;,&quot;2265&quot;,&quot;2266&quot;,&quot;2267&quot;,&quot;2268&quot;,&quot;2269&quot;,&quot;2270&quot;,&quot;2271&quot;,&quot;2272&quot;,&quot;2273&quot;,&quot;2274&quot;,&quot;2275&quot;,&quot;2276&quot;,&quot;2277&quot;,&quot;2278&quot;,&quot;2279&quot;,&quot;2280&quot;,&quot;2281&quot;,&quot;2282&quot;,&quot;2283&quot;,&quot;2284&quot;,&quot;2285&quot;,&quot;2286&quot;,&quot;2287&quot;,&quot;2288&quot;,&quot;2289&quot;,&quot;2290&quot;,&quot;2291&quot;,&quot;2292&quot;,&quot;2293&quot;,&quot;2294&quot;,&quot;2295&quot;,&quot;2296&quot;,&quot;2297&quot;,&quot;2298&quot;,&quot;2299&quot;,&quot;2300&quot;,&quot;2301&quot;,&quot;2302&quot;,&quot;2303&quot;,&quot;2304&quot;,&quot;2305&quot;,&quot;2306&quot;,&quot;2307&quot;,&quot;2308&quot;,&quot;2309&quot;,&quot;2310&quot;,&quot;2311&quot;,&quot;2312&quot;,&quot;2313&quot;,&quot;2314&quot;,&quot;2315&quot;,&quot;2316&quot;,&quot;2317&quot;,&quot;2318&quot;,&quot;2319&quot;,&quot;2320&quot;,&quot;2321&quot;,&quot;2322&quot;,&quot;2323&quot;,&quot;2324&quot;,&quot;2325&quot;,&quot;2326&quot;,&quot;2327&quot;,&quot;2328&quot;,&quot;2329&quot;,&quot;2330&quot;,&quot;2331&quot;,&quot;2332&quot;,&quot;2333&quot;,&quot;2334&quot;,&quot;2335&quot;,&quot;2336&quot;,&quot;2337&quot;,&quot;2338&quot;,&quot;2339&quot;,&quot;2340&quot;,&quot;2341&quot;,&quot;2342&quot;,&quot;2343&quot;,&quot;2344&quot;,&quot;2345&quot;,&quot;2346&quot;,&quot;2347&quot;,&quot;2348&quot;,&quot;2349&quot;,&quot;2350&quot;,&quot;2351&quot;,&quot;2352&quot;,&quot;2353&quot;,&quot;2354&quot;,&quot;2355&quot;,&quot;2356&quot;,&quot;2357&quot;,&quot;2358&quot;,&quot;2359&quot;,&quot;2360&quot;,&quot;2361&quot;,&quot;2362&quot;,&quot;2363&quot;,&quot;2364&quot;,&quot;2365&quot;,&quot;2366&quot;,&quot;2367&quot;,&quot;2368&quot;,&quot;2369&quot;],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,31,31,31,31,31,31,31,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,58,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,67,67,67,67,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68],[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,1,1,1,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,1,0,1,0,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0,0,1,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0],[1.252762968,0.832909123,2.079441542,1.435084525,-0.916290732,0.955511445,1.722766598,1.568615918,0.262364264,1.280933845,1.667706821,3.186352633,1.280933845,1.280933845,0.262364264,3.688879454,0.916290732,1.410986974,3.165475048,0.641853886,-0.356674944,0.741937345,0.916290732,0.875468737,0.641853886,0.262364264,-2.302585093,2.58021683,1.667706821,1.252762968,1.704748092,-0.693147181,0.875468737,1.916922612,0.530628251,0.262364264,0.693147181,1.791759469,-0.223143551,1.435084525,2.32238772,4.34120464,1.098612289,-0.356674944,0.405465108,0.262364264,2.917770732,1.223775432,0.832909123,-0.510825624,1.098612289,-0.693147181,2.954910279,3.891820298,0.587786665,3.650658241,1.098612289,2.197224577,1.223775432,0.641853886,0.993251773,0.78845736,0.916290732,-0.223143551,-0.105360516,-0.916290732,0.641853886,0.470003629,4.028916757,0.832909123,3.328626689,1.252762968,0.09531018,0.09531018,1.335001067,1.386294361,0.405465108,-0.916290732,0.09531018,1.824549292,2.079441542,1.131402111,1.887069649,1.648658626,2.442347035,1.547562509,0.530628251,1.808288771,2.261763098,-0.223143551,2.041220329,1.808288771,2.079441542,-0.223143551,0.182321557,2.557227311,1.223775432,0.741937345,0.262364264,-0.510825624,0.336472237,0.955511445,2.028148247,1.098612289,0,2.2300144,1.774952351,1.131402111,1.722766598,-0.510825624,1.223775432,1.131402111,0.182321557,0.993251773,1.931521412,1.064710737,-0.105360516,-0.223143551,-0.105360516,-0.693147181,1.252762968,0.09531018,0.916290732,1.335001067,0.641853886,1.902107526,0.182321557,0.405465108,3.000719815,0.530628251,1.064710737,1.029619417,0,0.955511445,1.386294361,0,-0.223143551,0.405465108,0.693147181,-0.105360516,-0.510825624,0.993251773,0.993251773,0.182321557,0.470003629,0.741937345,2.451005098,-0.223143551,1.16315081,1.193922468,0.955511445,1.280933845,2.587764035,0.336472237,0.78845736,1.808288771,0.741937345,0.78845736,1.648658626,0.470003629,1.62924054,1.064710737,0.470003629,1.029619417,1.064710737,0.09531018,0.262364264,0.78845736,2.116255515,0,1.589235205,0.336472237,0.916290732,0,1.252762968,0.182321557,0,1.360976553,2.041220329,0.09531018,1.62924054,0.832909123,0.09531018,2.90690106,-1.203972804,-0.356674944,-2.302585093,0.741937345,0.693147181,1.458615023,0.641853886,0.09531018,0.262364264,0.262364264,-0.223143551,0.182321557,2.116255515,0.182321557,-0.510825624,2.595254707,-0.223143551,1.526056303,0.587786665,1.30833282,0.875468737,1.722766598,0,2.970414466,2.32238772,1.808288771,1.547562509,0.405465108,0.09531018,-0.105360516,0.875468737,-0.693147181,0.09531018,0.09531018,0.182321557,0.336472237,0.470003629,-0.356674944,-0.693147181,0.741937345,2.00148,0.336472237,2.208274414,2.104134154,0.875468737,0.470003629,1.526056303,0.993251773,1.064710737,1.029619417,-0.105360516,-0.356674944,1.098612289,2.014903021,0.955511445,0,0.875468737,1.064710737,2.251291799,4.520701029,1.131402111,0.09531018,-0.510825624,0.916290732,0.641853886,0.405465108,0.993251773,0.262364264,1.223775432,-0.356674944,0.530628251,-0.510825624,-0.356674944,0.262364264,0,0.641853886,1.704748092,0.955511445,1.547562509,1.704748092,0.262364264,-0.916290732,1.458615023,2.397895273,1.722766598,0.262364264,2.261763098,2.57261223,1.547562509,2.332143895,3.572345638,1.30833282,1.360976553,0.182321557,1.481604541,1.609437912,4.032469159,2.104134154,0.530628251,1.280933845,0.993251773,1.609437912,0.336472237,0,0.530628251,-0.223143551,-1.203972804,2.174751721,0.875468737,0.405465108,-0.223143551,1.029619417,1.16315081,0.832909123,-0.693147181,0.530628251,-0.510825624,1.193922468,2.197224577,0.09531018,0.336472237,2.451005098,0.916290732,2.667228207,1.85629799,1.667706821,1.808288771,3.206803244,0.336472237,0.78845736,3.449987546,0.955511445,2.261763098,1.064710737,1.526056303,0.693147181,1.386294361,2.57261223,0.993251773,1.30833282,1.704748092,1.945910149,-0.356674944,1.029619417,0.875468737,2.014903021,2.944438979,1.808288771,0.993251773,2.028148247,1.481604541,1.360976553,2.186051277,3.005682604,1.30833282,2.970414466,0.641853886,1.458615023,0.832909123,1.504077397,0.993251773,0.78845736,3.206803244,1.458615023,3.443618098,3.465735903,2.433613355,2.00148,2.104134154,0.875468737,2.041220329,1.029619417,0.993251773,1.824549292,0.78845736,0.262364264,0.78845736,0.832909123,0.916290732,3.370738174,0.262364264,0.641853886,1.435084525,1.029619417,0.916290732,2.667228207,0.641853886,2.844909384,1.589235205,0.916290732,1.916922612,2.014903021,0.78845736,0.916290732,3.077312261,0.530628251,0.336472237,-1.203972804,1.458615023,0.405465108,-0.105360516,3.126760536,2.104134154,1.840549633,2.091864062,3.380994674,2.128231706,1.30833282,3.526360525,0.741937345,0.955511445,4.001863709,1.16315081,1.30833282,2.292534757,3.414442608,1.808288771,1.30833282,1.16315081,0.182321557,0.262364264,0.693147181,1.568615918,0.693147181,-0.916290732,1.504077397,1.098612289,1.30833282,1.252762968,1.974081026,0.693147181,1.547562509,-1.609437912,0.693147181,1.609437912,1.648658626,1.280933845,0.832909123,2.174751721,1.131402111,0.405465108,1.974081026,0.336472237,-0.693147181,4.639571613,2.079441542,0.641853886,0.262364264,0.587786665,1.667706821,2.701361213,2.766319109,1.131402111,0.182321557,2.541601993,1.757857918,1.589235205,3.250374492,0.587786665,-0.105360516,1.757857918,2.985681938,0.182321557,2.839078464,1.589235205,1.808288771,0.587786665,0.262364264,0.832909123,0.182321557,2.282382386,0.916290732,3.538056564,2.2300144,-0.693147181,2.140066163,-0.510825624,2.970414466,1.029619417,0,0.530628251,1.568615918,0.955511445,1.960094784,3.0301337,2.740840024,2.379546134,0.262364264,2.292534757,3.471966453,4.222444565,2.610069793,2.00148,2.442347035,-2.302585093,2.251291799,3.165475048,0.916290732,1.435084525,1.547562509,1.722766598,2.624668592,0.470003629,0.530628251,0.405465108,0.916290732,1.481604541,0.09531018,0.832909123,0.916290732,0.262364264,0.182321557,0.405465108,-1.203972804,1.686398954,2.163323026,0.916290732,0.262364264,-0.356674944,-0.693147181,0,1.131402111,1.335001067,1.840549633,1.064710737,2.00148,3.261935314,2.397895273,1.916922612,0.875468737,0.262364264,-0.510825624,1.335001067,2.433613355,2.186051277,-0.510825624,2.054123734,0.182321557,-1.609437912,1.131402111,1.458615023,2.197224577,0,0.530628251,2.261763098,1.648658626,0.955511445,-1.203972804,1.62924054,3.407841924,1.808288771,1.410986974,2.809402695,0.470003629,3.912023005,1.360976553,2.610069793,2.809402695,-0.105360516,2.844909384,0.741937345,1.504077397,2.174751721,0.530628251,0.530628251,0.641853886,1.887069649,1.974081026,0,0.78845736,2.219203484,1.871802177,1.840549633,3.414442608,1.808288771,2.501435952,2.541601993,2.292534757,1.386294361,0.641853886,1.704748092,0.405465108,1.386294361,1.360976553,0.641853886,2.525728644,0.182321557,0.993251773,1.193922468,0.832909123,0.09531018,2.341805806,0,1.757857918,1.62924054,1.526056303,1.131402111,-0.510825624,2.091864062,0.993251773,-1.609437912,2.014903021,0.955511445,1.16315081,2.041220329,-0.693147181,-0.356674944,3.502549876,0.641853886,-0.223143551,1.064710737,0.741937345,0.916290732,0.78845736,1.704748092,1.30833282,0.470003629,0,1.098612289,0.262364264,0.262364264,0.336472237,0.693147181,3.058707073,1.30833282,0.470003629,3.46260601,1.504077397,3.424262655,3.280911216,1.740466175,0.875468737,3.08190997,1.648658626,2.653241965,3.342861805,3.353406718,-0.510825624,3.484312288,2.360854001,1.589235205,-0.693147181,1.410986974,1.757857918,1.386294361,1.029619417,1.945910149,0.587786665,0,-0.356674944,0.182321557,0.641853886,1.887069649,3.47506723,2.721295428,1.526056303,0.182321557,-2.302585093,2.251291799,0,0.470003629,1.62924054,2.219203484,1.568615918,-0.356674944,2.197224577,3.414442608,2.667228207,2.014903021,-0.510825624,1.386294361,4.001863709,-0.693147181,0.78845736,0.955511445,1.481604541,0.09531018,1.458615023,1.410986974,2.517696473,2.054123734,1.16315081,0.78845736,1.686398954,0.875468737,0.336472237,-0.223143551,2.2300144,0.530628251,1.335001067,1.987874348,3.421000009,3.218875825,1.974081026,-0.105360516,0.78845736,3.299533728,1.916922612,0.916290732,1.029619417,0.470003629,0.530628251,0.875468737,2.261763098,1.252762968,-0.693147181,0.693147181,0.470003629,1.064710737,0.693147181,2.660259537,2.895911938,1.029619417,0,0.916290732,4.310799125,1.410986974,1.193922468,1.987874348,-0.223143551,0.182321557,1.223775432,0.405465108,1.902107526,0.530628251,2.104134154,1.871802177,2.954910279,1.193922468,1.568615918,0.78845736,2.32238772,-0.510825624,0.641853886,0.741937345,0.405465108,0.262364264,0.405465108,0.641853886,2.839078464,0.78845736,0.693147181,-0.105360516,1.648658626,0.182321557,0.470003629,0.993251773,2.76000994,1.131402111,-0.356674944,0.916290732,-0.223143551,-0.510825624,0.693147181,-0.223143551,0,0.587786665,0.693147181,1.774952351,2.251291799,0.336472237,-0.223143551,1.547562509,2.803360381,1.931521412,1.648658626,2.890371758,1.410986974,1.223775432,2.960105096,3.749504076,1.193922468,0.09531018,1.098612289,0.262364264,-0.356674944,0.405465108,2.646174797,0.641853886,2.272125886,2.104134154,2.028148247,4.49088104,2.533696814,1.740466175,0.916290732,1.887069649,2.653241965,2.895911938,2.272125886,1.386294361,2.766319109,2.895911938,1.481604541,2.104134154,1.722766598,0.955511445,2.208274414,1.098612289,3.919991175,1.458615023,0.182321557,4.163559631,1.280933845,3.788724789,2.282382386,1.029619417,1.131402111,1.481604541,1.223775432,3.777348102,3.561046083,1.064710737,1.064710737,0.405465108,1.280933845,1.280933845,0.78845736,1.029619417,1.547562509,2.054123734,-1.203972804,-0.356674944,1.335001067,-2.302585093,0.405465108,-0.105360516,-0.105360516,2.251291799,-0.356674944,2.766319109,0.832909123,3.100092289,1.686398954,0.09531018,0.741937345,-0.356674944,-0.223143551,1.526056303,1.916922612,0.741937345,1.808288771,2.879198457,1.064710737,-0.510825624,1.410986974,1.064710737,0.405465108,0.262364264,-0.223143551,2.468099531,1.335001067,3.80666249,1.386294361,2.116255515,1.808288771,1.131402111,1.547562509,-0.223143551,0.587786665,0,0.336472237,2.360854001,1.029619417,-0.105360516,0.09531018,1.335001067,0.693147181,1.131402111,2.525728644,1.960094784,1.252762968,-0.356674944,0.470003629,1.064710737,2.014903021,-0.916290732,-1.203972804,-1.203972804,3.891820298,1.686398954,1.029619417,3.433987204,2.734367509,0.741937345,2.32238772,2.312535424,1.887069649,0.09531018,1.386294361,4.520701029,-0.510825624,0.09531018,1.774952351,-0.105360516,1.098612289,-0.223143551,0.336472237,0.78845736,0.78845736,1.280933845,-0.223143551,1.16315081,-0.105360516,0.262364264,2.424802726,0.470003629,-0.916290732,0.405465108,0.741937345,1.871802177,2.054123734,0.693147181,1.481604541,1.568615918,2.197224577,2.815408719,1.791759469,1.386294361,2.415913778,1.667706821,3.374168709,2.128231706,0.262364264,1.902107526,2.415913778,1.974081026,2.533696814,0.641853886,0.993251773,1.223775432,4.195697056,1.960094784,1.335001067,4.248495242,5.051777237,2.701361213,2.617395833,3.895893623,3.010620886,4.273884476,3.822098298,3.186352633,3.034952987,2.397895273,1.131402111,1.85629799,3.210843653,1.30833282,2.595254707,1.410986974,0.530628251,3.777348102,1.526056303,2.624668592,1.704748092,0.09531018,1.648658626,2.714694744,0.530628251,-0.916290732,2.57261223,2.949688335,0.832909123,3.718438256,5.611301622,0.09531018,2.240709689,1.410986974,0.741937345,1.740466175,2.844909384,2.90690106,1.029619417,0.262364264,1.223775432,2.459588842,0.09531018,2.525728644,0.262364264,3.411147713,3.310543013,2.674148649,1.193922468,-0.510825624,2.602689685,3.33220451,5.12455904,4.302712828,3.025291076,3.36729583,0.262364264,2.954910279,0.693147181,-0.105360516,2.58021683,0.09531018,4.587006215,1.791759469,1.360976553,2.844909384,4.183575696,2.251291799,1.504077397,1.098612289,3.27336401,0.336472237,0.955511445,-2.302585093,0.470003629,0.916290732,-2.302585093,-0.510825624,-0.916290732,0.955511445,-0.693147181,-2.302585093,0.916290732,1.280933845,-0.510825624,1.064710737,0.741937345,-0.105360516,0.262364264,2.468099531,2.219203484,-0.693147181,0,-1.203972804,-0.105360516,-0.105360516,0.955511445,0.875468737,-0.916290732,1.481604541,-0.356674944,0.587786665,0.09531018,0,1.193922468,0,0.336472237,5.564137192,0.336472237,0.470003629,-1.609437912,2.312535424,1.252762968,0.741937345,3.198673118,-0.223143551,1.131402111,1.029619417,-0.223143551,-0.356674944,-0.916290732,1.029619417,1.360976553,0,-0.693147181,3.826465117,1.458615023,-0.223143551,-1.609437912,2.772588722,2.174751721,0.916290732,0.336472237,0.405465108,0.693147181,0.470003629,1.667706821,1.960094784,2.104134154,3.202746443,-2.302585093,2.541601993,0.262364264,-1.609437912,2.468099531,0,-2.302585093,0,0.530628251,-2.302585093,1.648658626,3.18221184,3.45946629,0.875468737,-0.223143551,1.808288771,2.054123734,1.667706821,-0.693147181,-0.223143551,0.182321557,1.360976553,-0.105360516,0.336472237,1.280933845,1.774952351,-1.609437912,-0.105360516,0.530628251,0.262364264,1.960094784,0.262364264,2.128231706,0.741937345,0.262364264,-0.916290732,2.57261223,-0.223143551,-0.510825624,-0.356674944,2.76000994,0.262364264,0.641853886,0.641853886,-0.916290732,-0.510825624,-0.916290732,-0.105360516,-0.105360516,-0.223143551,0.405465108,1.386294361,-0.510825624,-0.510825624,-0.916290732,2.541601993,1.386294361,-0.356674944,0.182321557,0.530628251,0.641853886,3.010620886,1.589235205,-0.105360516,-0.693147181,0.78845736,1.193922468,3.091042453,-0.105360516,1.064710737,-0.356674944,2.272125886,0.641853886,2.00148,1.252762968,0.262364264,0.530628251,0.470003629,2.90690106,0.470003629,0.530628251,-0.223143551,0.405465108,1.098612289,3.18221184,1.252762968,3.817712326,2.370243741,0.530628251,3.33220451,2.197224577,2.557227311,2.862200881,2.965273066,0.336472237,0.875468737,1.335001067,2.388762789,2.884800713,2.501435952,-0.223143551,1.648658626,2.985681938,0.832909123,1.435084525,2.76000994,4.168214411,0.470003629,0.832909123,-2.302585093,1.193922468,1.648658626,1.757857918,-0.223143551,-0.105360516,1.740466175,0.641853886,1.85629799,0.916290732,1.098612289,2.282382386,1.840549633,2.753660712,0.09531018,0.09531018,0.693147181,0.182321557,1.458615023,0.641853886,0.182321557,1.223775432,0,2.00148,3.258096538,0.262364264,0.182321557,2.610069793,0.262364264,1.064710737,2.341805806,2.079441542,1.360976553,1.686398954,2.990719732,-0.223143551,0.916290732,-0.510825624,1.871802177,2.251291799,2.332143895,0.832909123,2.379546134,0.916290732,0.470003629,0.530628251,-0.223143551,2.272125886,0.741937345,1.131402111,0,0.09531018,0.470003629,2.054123734,-0.105360516,0.405465108,1.945910149,1.386294361,0.182321557,-0.105360516,0.262364264,-0.223143551,0.405465108,2.140066163,0,-2.302585093,-0.356674944,0.741937345,0.182321557,1.458615023,-0.105360516,1.648658626,1.193922468,-1.203972804,1.547562509,1.902107526,0.336472237,1.335001067,-0.510825624,0.78845736,0.262364264,-0.693147181,0.955511445,1.824549292,1.098612289,0.955511445,1.547562509,0.182321557,1.131402111,0,0.182321557,0.09531018,0.182321557,1.360976553,0,1.722766598,2.140066163,-0.356674944,-0.510825624,1.335001067,0.641853886,-0.510825624,1.360976553,0.693147181,0.336472237,-0.105360516,-0.356674944,1.410986974,1.064710737,0.641853886,0.336472237,0.262364264,2.4765384,-0.223143551,1.435084525,0.641853886,0.832909123,1.064710737,-0.356674944,0.587786665,0.336472237,0.09531018,1.131402111,2.00148,1.360976553,-0.223143551,0,0.916290732,2.517696473,1.609437912,2.57261223,2.066862759,1.85629799,1.808288771,3.310543013,1.16315081,1.568615918,2.251291799,2.985681938,2.912350665,0.405465108,1.945910149,3.131136911,2.079441542,2.797281335,3.317815773,4.660604893,2.772588722,2.797281335,2.251291799,3.095577609,1.568615918,1.757857918,3.411147713,3.591817741,2.351375257,2.219203484,1.458615023,2.76000994,2.587764035,0.993251773,2.116255515,1.931521412,2.564949357,2.990719732,2.174751721,3.555348061,1.648658626,2.240709689,2.282382386,0.641853886,1.871802177,2.541601993,1.774952351,3.889777396,2.151762203,2.406945108,2.442347035,4.198704578,2.694627181,2.406945108,3.532225644,1.808288771,1.547562509,1.740466175,1.568615918,0.405465108,2.028148247,1.704748092,1.098612289,2.2300144,2.76000994,2.2300144,0.693147181,2.687847494,1.098612289,1.193922468,0.09531018,0.693147181,-0.356674944,0.405465108,-2.302585093,1.098612289,1.648658626,0.182321557,1.16315081,1.526056303,0.262364264,0.530628251,1.223775432,0.262364264,0.182321557,1.609437912,0,0.262364264,0.741937345,2.197224577,0.405465108,1.667706821,0.182321557,1.16315081,0,0.693147181,-0.105360516,1.223775432,1.504077397,0.336472237,0.916290732,1.589235205,1.335001067,1.871802177,0.832909123,0.336472237,0.832909123,2.890371758,0.405465108,0.955511445,0,0.693147181,2.292534757,0.405465108,2.104134154,1.589235205,1.686398954,0.916290732,2.370243741,2.595254707,-0.916290732,0.993251773,1.335001067,2.282382386,2.595254707,3.234749174,1.029619417,5.281679725,3.020424886,2.48490665,2.442347035,3.552486829,2.302585093,2.32238772,1.791759469,2.442347035,2.140066163,2.509599262,3.873282177,1.360976553,2.778819272,2.602689685,2.151762203,2.186051277,1.131402111,1.648658626,2.397895273,3.339321978,2.912350665,1.740466175,1.609437912,1.131402111,3.589059119,3.843744165,1.757857918,2.2300144,1.757857918,1.547562509,2.564949357,0.182321557,3.660994251,2.261763098,-0.693147181,2.140066163,4.356708827,1.974081026,1.62924054,3.161246712,1.871802177,-1.203972804,2.557227311,-0.510825624,0.832909123,0.182321557,0.262364264,0.182321557,0.09531018,1.435084525,0.875468737,1.824549292,-0.105360516,-0.105360516,1.840549633,0.530628251,1.098612289,0.693147181,0.993251773,2.116255515,3.100092289,0.832909123,0.993251773,0.693147181,1.335001067,0.916290732,2.533696814,0.470003629,1.435084525,1.589235205,2.397895273,-0.693147181,0.875468737,1.064710737,0.693147181,1.252762968,0.693147181,1.131402111,0.262364264,0.530628251,0.336472237,0.182321557,0.09531018,1.252762968,0.262364264,0.875468737,2.867898902,0.693147181,-0.510825624,2.151762203,1.960094784,0.916290732,1.589235205,0.875468737,1.609437912,-0.105360516,2.564949357,1.386294361,0.78845736,0.641853886,0.530628251,-0.105360516,0.470003629,0.955511445,0.405465108,0.405465108,0.832909123,0.993251773,0.955511445,1.029619417,2.721295428,0.262364264,0.641853886,2.054123734,1.252762968,0.262364264,0.875468737,-0.510825624,-0.356674944,0.587786665,0.405465108,0.955511445,0.09531018,1.740466175,0.530628251,1.871802177,0.09531018,2.261763098,0.955511445,0.530628251,1.686398954,0.955511445,0.587786665,1.458615023,0.262364264,1.547562509,0.741937345,-0.105360516,0,0.587786665,0.587786665,-0.105360516,-0.105360516,-0.693147181,0.530628251,0.955511445,1.960094784,0.875468737,0.182321557,2.251291799,2.116255515,0.530628251,0.78845736,1.098612289,0.741937345,-0.693147181,2.028148247,1.410986974,-0.916290732,1.960094784,-0.223143551,1.098612289,0.955511445,0.336472237,1.740466175,1.458615023,0.09531018,0.832909123,2.415913778,1.360976553,4.188138442,0.470003629,2.240709689,1.435084525,1.16315081,0.587786665,0.336472237,2.753660712,1.223775432,4.348986781,0.587786665,0.182321557,3.985273467,2.028148247,0.916290732,1.791759469,1.526056303,0.641853886,0.530628251,0.875468737,-2.302585093,-0.916290732,-1.203972804,-0.693147181,-0.105360516,0.262364264,1.704748092,2.944438979,1.410986974,0.993251773,0.832909123,-1.203972804,-0.105360516,0.78845736,1.481604541,0.262364264,-0.105360516,-0.105360516,0.955511445,1.360976553,1.85629799,1.252762968,1.16315081,4.536891345,2.533696814,0.741937345,0.641853886,0.182321557,0.262364264,0.641853886,0.530628251,-0.510825624,-0.510825624,0,1.335001067,0.955511445,1.16315081,1.30833282,0.262364264,1.686398954,0.741937345,0.587786665,0.336472237,0.182321557,-0.223143551,0.955511445,0.530628251,0.336472237,0.78845736,-0.105360516,1.064710737,-0.105360516,-0.223143551,2.493205453,2.272125886,1.131402111,0.530628251,1.30833282,2.091864062,0.470003629,-0.356674944,1.686398954,1.193922468,0.641853886,-0.223143551,0.530628251,0.641853886,3.618993327,2.517696473,0.336472237,2.63188884,1.458615023,2.140066163,1.223775432,3.377587516,3.104586678,1.131402111,1.568615918,-0.510825624,2.360854001,0.470003629,0.955511445,2.00148,-0.693147181,2.827313622,4.151039906,-0.356674944,-0.356674944,1.504077397,1.609437912,1.064710737,-0.916290732,0.470003629,1.722766598,2.091864062,0.182321557,1.098612289,3.054001182,0.405465108,1.064710737,1.808288771,2.557227311,-0.693147181,2.58021683,2.041220329,2.312535424,1.16315081,2.054123734,2.282382386,1.131402111,0.916290732,2.58021683,2.687847494,1.481604541,3.46885603,-0.223143551,1.029619417,0.875468737,0.875468737,1.252762968,-0.105360516,0.955511445,2.186051277,0.693147181,0,1.547562509,0.470003629,1.945910149,2.219203484,1.62924054,1.30833282,1.609437912,0.916290732,-0.223143551,0.875468737,0.875468737,2.174751721,0.955511445,1.360976553,-0.356674944,1.335001067,2.116255515,1.193922468,1.386294361,0.262364264,1.16315081,0.78845736,1.757857918,0.78845736,0.405465108,1.62924054,-0.223143551,-0.105360516,0.875468737,0.09531018,0.09531018,-2.302585093,1.609437912,0.336472237,1.335001067,1.098612289,0.832909123,-0.223143551,0.09531018,0.09531018,0.262364264,0.955511445,1.871802177,1.131402111,0.09531018,1.481604541,1.945910149,1.481604541,-0.916290732,-0.356674944,-0.510825624,2.57261223,1.589235205,1.504077397,0.832909123,1.704748092,1.064710737,4.298645026,0.262364264,3.711130063,2.63188884,1.568615918,2.028148247,2.028148247,1.791759469,1.704748092,3.044522438,3.740047741,2.312535424,2.208274414,1.791759469,2.63188884,1.481604541,1.902107526,2.360854001,2.00148,1.840549633,2.809402695,1.526056303,0.875468737,3.94931879,1.740466175,-0.693147181,2.856470206,0.641853886,0.470003629,0.336472237,4.378269586,1.931521412,1.757857918,1.029619417,2.091864062,2.778819272,2.867898902,1.568615918,1.131402111,2.388762789,0.741937345,0.530628251,3.725693427,2.797281335,0.832909123,-2.302585093,-0.356674944,1.280933845,-0.105360516,0.993251773,0.875468737,1.064710737,0.641853886,1.029619417,-0.356674944,-1.203972804,-0.356674944,0.993251773,0.693147181,0.78845736,2.76000994,-0.693147181,-0.356674944,-0.510825624,0.405465108,1.029619417,0.832909123,0.741937345,0.09531018,-0.916290732,1.526056303,1.30833282,1.16315081,0.741937345,0.875468737,0.641853886,0.405465108,-0.693147181,0.955511445,-1.203972804,0.587786665,-0.223143551,0.530628251,-0.510825624,0.530628251,0.693147181,-0.356674944,0.470003629,-1.203972804,1.704748092,-0.510825624,2.564949357,-0.916290732,1.335001067,1.458615023,3.629660094,1.686398954,0.09531018,0.405465108,1.131402111,1.757857918,0.470003629,-0.693147181,-0.510825624,1.029619417,0.832909123,1.223775432,0.09531018,-0.105360516,1.504077397,-1.609437912,0.262364264,-0.693147181,-0.916290732,0.587786665,0.09531018,0,0.587786665,0.182321557,-0.693147181,-0.223143551,0.530628251,-1.609437912,0.182321557,0.405465108,-0.693147181,1.360976553,-0.916290732,-1.203972804,-0.693147181,0.693147181,0.262364264,-1.609437912,-0.356674944,-0.356674944,1.85629799,0.262364264,0.78845736,0.993251773,1.16315081,0.470003629,1.85629799,0.641853886,1.704748092,0.09531018,-0.105360516,0.693147181,1.16315081,0,0.09531018,0.09531018,0.741937345,0.182321557,0.587786665,0.262364264,1.722766598,-0.693147181,0.78845736,0.182321557,-0.223143551,-1.203972804,-0.105360516,-1.609437912,0.916290732,0.741937345,0.405465108,-0.693147181,1.481604541,-0.105360516,0.182321557,-0.356674944,-0.693147181,1.098612289,2.797281335,1.960094784,0.832909123,1.931521412,-0.693147181,-0.693147181,-0.223143551,2.208274414,1.410986974,0.587786665,5.425830687,0.587786665,1.704748092,1.280933845,1.193922468,5.109575242,1.098612289,1.504077397,1.098612289,-0.916290732,0.182321557,-0.510825624,3.990834186,2.2300144,1.62924054,0.875468737,2.066862759,3.299533728,0.336472237,3.756538103,0.09531018,3.645449896,-0.510825624,-1.203972804,-0.916290732,2.00148,0.832909123,2.928523524,2.054123734,3.779633817,0.336472237,0.78845736,1.360976553,1.526056303,0.262364264,0.587786665,2.332143895,3.73289634,2.041220329,2.174751721,1.504077397,4.295923936,-0.356674944,2.653241965,2.041220329,2.116255515,0.693147181,3.899950424,0.587786665,1.386294361,1.029619417,-0.916290732,-0.223143551,0.09531018,0.641853886,1.252762968,1.16315081,1.16315081,1.410986974,0.78845736,1.098612289,0.693147181,1.945910149,3.295836866,2.388762789,-2.302585093,0.182321557,0.09531018,0.336472237,1.064710737,1.808288771,0.693147181,1.064710737,0.09531018,-0.510825624,0.336472237,0.955511445,2.351375257,-0.105360516,0.993251773,0.955511445,1.871802177,0.78845736,2.433613355,1.667706821,1.667706821,2.694627181,2.856470206,0.693147181,-0.223143551,-0.223143551,-0.223143551,0.78845736,1.589235205,-0.223143551,1.435084525,4.249922794,-0.356674944,1.223775432,-1.203972804,-0.356674944,0,0.470003629,2.00148,1.757857918,0.875468737,1.193922468,0.470003629,-0.356674944,3.317815773,3.148453361,-0.510825624,0.470003629,1.435084525,-1.203972804,3.126760536,0.470003629,-0.510825624,3.881563798,0.182321557,0.693147181,1.902107526,2.525728644,1.902107526,0,2.208274414,2.442347035,5.482304203,0.693147181,0.470003629,0.916290732,3.860729711,2.912350665,0.336472237,-0.356674944,0.530628251,2.00148,2.653241965,3.113515309,1.386294361,1.131402111,1.098612289,2.014903021,-1.203972804,0.832909123,2.32238772,1.064710737,1.16315081,0.405465108,-0.105360516,1.458615023,0.405465108,0.336472237,0.09531018,1.223775432,-0.510825624,1.931521412,-0.693147181,-1.203972804,0.587786665,-0.105360516,-0.223143551,3.39785848,2.219203484,-0.223143551,2.041220329,2.116255515,0.832909123,0.336472237,0.587786665,0.78845736,0.470003629,0.587786665,0.336472237,0.641853886,-0.693147181,0.875468737,0.587786665,0.405465108,0.405465108,0.470003629,0.587786665,-0.223143551,3.020424886,1.435084525,-0.693147181,2.610069793,0.530628251,0.587786665,1.280933845,0.182321557,2.493205453,0.470003629,0.470003629,1.887069649,0.262364264,0.182321557,1.887069649,1.360976553,2.282382386,1.252762968,-2.302585093,0.78845736,2.2300144,0.741937345,0.741937345,1.704748092,1.098612289,0.262364264,-2.302585093,0.955511445,0.182321557,2.610069793,1.064710737,0.641853886,1.547562509,1.648658626,0.587786665,2.151762203,1.504077397,0.262364264,0.336472237,0.641853886,0.993251773,-0.510825624,-0.510825624,2.57261223,1.589235205,-1.609437912,0.09531018,-0.105360516,0.182321557,0,-1.609437912,-0.105360516,-0.916290732,1.131402111,0.262364264,0.78845736,0.182321557,3.126760536,-0.356674944,-1.203972804,-2.302585093,0.405465108,0.641853886,2.282382386,0.741937345,0.336472237,-0.223143551,0.530628251,0.641853886,-0.105360516,0.09531018,1.791759469,1.916922612,1.029619417,-0.105360516,2.140066163,1.458615023,0.09531018,1.335001067,1.547562509,2.653241965,1.458615023,1.193922468,1.85629799,1.064710737,1.16315081,2.32238772,0,1.62924054,2.00148,-0.356674944,0.741937345,2.219203484,-0.916290732,0.741937345,0.530628251,1.064710737,-0.105360516,2.028148247,-0.105360516,3.535145354,-0.105360516,1.704748092,0.741937345,2.451005098,-2.302585093,2.292534757,1.30833282,1.410986974,2.360854001,1.252762968,0.530628251,2.140066163,0.832909123,0.530628251,0.262364264,1.280933845,1.193922468,-0.693147181,0.09531018,1.589235205,0,0.470003629,1.481604541,1.887069649,0.336472237,0.336472237,0.336472237,1.824549292,1.280933845,0.530628251,0.78845736,0.641853886,1.16315081,0.336472237,0.405465108,-0.356674944,0.916290732,0.587786665,0.693147181,0.470003629,3.854393893,2.163323026,2.433613355,1.458615023,-0.223143551,2.151762203,2.509599262,0.405465108,3.61361697,1.740466175,1.568615918,2.186051277,2.93385687,1.193922468,0.405465108,4.197201948,1.098612289,1.589235205,2.93385687,5.047288612,0.587786665,1.064710737,4.529368473,-0.105360516,0.336472237,-0.105360516,1.064710737,2.240709689,0.78845736,3.113515309,2.549445171,3.832979798,2.104134154,2.541601993,3.19047635,1.667706821,3.517497837,1.887069649,1.029619417,4.027135813,1.458615023,1.16315081,1.887069649,1.902107526,1.335001067,2.617395833,1.386294361,0.875468737,2.251291799,4.228292535,1.589235205,1.064710737,2.602689685,3.169685581,2.995732274,0.182321557,1.648658626,1.360976553,3.42751469,2.116255515,1.871802177,1.945910149,2.646174797,1.648658626,0.336472237,3.068052935,3.054001182],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10]],&quot;container&quot;:&quot;&lt;table class=\&quot;display\&quot;&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th&gt; &lt;\/th&gt;\n      &lt;th&gt;county&lt;\/th&gt;\n      &lt;th&gt;floor&lt;\/th&gt;\n      &lt;th&gt;radon&lt;\/th&gt;\n      &lt;th&gt;cgroup&lt;\/th&gt;\n    &lt;\/tr&gt;\n  &lt;\/thead&gt;\n&lt;\/table&gt;&quot;,&quot;options&quot;:{&quot;columnDefs&quot;:[{&quot;className&quot;:&quot;dt-right&quot;,&quot;targets&quot;:[1,2,3,4]},{&quot;orderable&quot;:false,&quot;targets&quot;:0}],&quot;order&quot;:[],&quot;autoWidth&quot;:false,&quot;orderClasses&quot;:false}},&quot;evals&quot;:[],&quot;jsHooks&quot;:[]}&lt;/script&gt;</code></pre>
<p>??? see the example 2 , the response variable is radon which means one kind of harmful substance’s concentration. the independent variable is county and floor. as you could see there are 68 county, and the floor of 0 row means the concentration of radon on the ground , 1 means the concentration of radon on the first floor. don’t care about the cgroup, it would not be used in this example. our question is about : is the concentration of radon different from the ground and the first floor???? — class: center, middle # modeol 1 ## linear model ??? first we try to buid the simplest model</p>
<table style="width:6%;">
<colgroup>
<col width="5%" />
</colgroup>
<tbody>
<tr class="odd">
<td>.panelset[ .panel[.panel-name[Code-lm]</td>
</tr>
<tr class="even">
<td>```r radon &lt;- read.csv(‘E:/academic_resources/note-tutorial/data/Radon_Data_RB.csv’, h=TRUE) radon<span class="math inline">\(floor &lt;- as.factor(radon\)</span>floor) radon<span class="math inline">\(county &lt;- as.factor(radon\)</span>county) radon<span class="math inline">\(cgroup &lt;- as.factor(radon\)</span>cgroup)</td>
</tr>
<tr class="odd">
<td>mod.radon.lm1 &lt;- lm(radon~floor, data=radon)</td>
</tr>
<tr class="even">
<td>summary(mod.radon.lm1) ``` ]</td>
</tr>
<tr class="odd">
<td>.panel[.panel-name[Result-lm]</td>
</tr>
<tr class="even">
<td>```</td>
</tr>
<tr class="odd">
<td>Call: lm(formula = radon ~ floor, data = radon)</td>
</tr>
<tr class="even">
<td>Residuals: Min 1Q Median 3Q Max -3.5419 -0.8338 -0.1407 0.7888 4.3720</td>
</tr>
<tr class="odd">
<td>Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.23931 0.02629 47.145 &lt;2e-16 <strong><em> floor1 -0.74801 0.08125 -9.207 &lt;2e-16 </em></strong></td>
</tr>
</tbody>
</table>
<p>Signif. codes: 0 ‘<em><strong>’ 0.001 ’</strong>’ 0.01 ’</em>’ 0.05 ‘.’ 0.1 ’ ’ 1</p>
<p>Residual standard error: 1.211 on 2367 degrees of freedom Multiple R-squared: 0.03457, Adjusted R-squared: 0.03417 F-statistic: 84.76 on 1 and 2367 DF, p-value: &lt; 2.2e-16</p>
<pre><code>]
]
???
- C-l: put all the data to the matrix called radon,set the Categorical Variable as factor, Write the fomular for the linear model, y is radon, x is floor, and the data we use from the matrix of radon, use the function summary to answer our question.
- R-l: the p value told us :yes!! about the concentration of radon, there a huge diffence between the ground and first floor!! so do you think these results are correct???????? NO!!!note the value of R-squared, only 0.03!!!! this means the linear relationship between y and x explains only 0.03 of the total variation in y！！in another words， the model we build almost can not  explain the data we have !! such kind of problem of would appear just because our model too simple and at the same time, the number of our samples are too much, see back sheet！！！we have more than two thousands samples, when model is simple ,but the number of sample is large, we get very samll standard error, and then we get  very small p value, so no matter what is the real relationship between x and y, when we have a lot of samples ,the p value is always significant, but the model is Inappropriate!!!!so how could we deal with the problem??

---
class: center, middle
# &lt;font color=red&gt;add the  independent variable !!! &lt;/font&gt;
???
just add more independent variable!
---
class: center, middle
# modeol 2
## linera mixed model
???
and let&#39;s build another model
---
.panelset[
.panel[.panel-name[Code-plot]

```r
library(ggplot2)
#right image
ggplot(data=radon, aes(x=floor, y=radon)) + geom_point() + geom_smooth(method=&#39;lm&#39;)
#left image
ggplot(data=radon, aes(x=floor, y=radon, group=county)) +
  geom_point() +
  geom_smooth(method=&#39;lm&#39;) +
  facet_wrap(~county) 
#Random effect and fixed effect????</code></pre>
<p>]</p>
<p>.panel[.panel-name[plot]</p>
<p>.pull-left[ <img src="figure/AdvanceSta-slides.rmd/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" />]</p>
<p>.pull-right[ <img src="figure/AdvanceSta-slides.rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" />] ]</p>
<p>.panel[.panel-name[Code-lmer1]</p>
<pre class="r"><code>library(lme4)
mod.radon.lmer1 &lt;- lmer(radon~floor + (1|county), data=radon)
summary(mod.radon.lmer1) </code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-lmer1]</p>
<pre><code>Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: radon ~ floor + (1 | county)
   Data: radon

REML criterion at convergence: 7282.9

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.5868 -0.6617 -0.0608  0.5875  4.0997 

Random effects:
 Groups   Name        Variance Std.Dev.
 county   (Intercept) 0.2567   0.5067  
 Residual             1.1997   1.0953  
Number of obs: 2369, groups:  county, 68

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.33689    0.06981   19.15
floor1      -0.79302    0.07507  -10.56

Correlation of Fixed Effects:
       (Intr)
floor1 -0.125</code></pre>
<p>]</p>
<p>.panel[.panel-name[Code-lmer2]</p>
<pre class="r"><code>library(lme4)
mod.radon.lmer2 &lt;- lmer(radon ~ floor + (1+floor|county), data=radon)
summary(mod.radon.lmer2) </code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-lmer2]</p>
<pre><code>Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: radon ~ floor + (1 + floor | county)
   Data: radon

REML criterion at convergence: 7281.6

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.5980 -0.6563 -0.0527  0.5868  4.1084 

Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 county   (Intercept) 0.26355  0.5134        
          floor1      0.03661  0.1913   -0.35
 Residual             1.19632  1.0938        
Number of obs: 2369, groups:  county, 68

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.34126    0.07063   18.99
floor1      -0.81147    0.08077  -10.05

Correlation of Fixed Effects:
       (Intr)
floor1 -0.217</code></pre>
<p>] .panel[.panel-name[Compare-value] .pull-left[</p>
<pre class="r"><code>rbind(fixef(mod.radon.lmer1),fixef(mod.radon.lmer2))</code></pre>
<pre><code>     (Intercept)     floor1
[1,]    1.336888 -0.7930172
[2,]    1.341265 -0.8114683</code></pre>
<p>] .pull-right[</p>
<pre class="r"><code>VarCorr(mod.radon.lmer1) </code></pre>
<pre><code> Groups   Name        Std.Dev.
 county   (Intercept) 0.50669 
 Residual             1.09531 </code></pre>
<pre class="r"><code>VarCorr(mod.radon.lmer2)</code></pre>
<pre><code> Groups   Name        Std.Dev. Corr  
 county   (Intercept) 0.51338        
          floor1      0.19133  -0.345
 Residual             1.09376        </code></pre>
<p>] ]</p>
<p>.panel[.panel-name[Compare-plot] <img src="figure/AdvanceSta-slides.rmd/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" />] ] ??? - C-p！！！before we buid the linear mixed model, we plot first . we draw the right image, the black points is the raw data of radon and floor, and we would use the lm method to draw the line in oder to show the relationship of radon bwtween the ground and floor 1, PLOT!!! - PLOT!!!as we could see, in the linear model , the concentration of radon on the groud is higher!!!! but we should know these more than two thousands date from more than 60 county!!and we have already known the lm model is not appropriate. so when we plot the image according to the different county, we would find in some county ,the concentration of radon on first floor is higher! but in some county ,there is no difference, and even in some county a lot of data is missing. so we could see clearly the variable of county has a great influence on the the relationship about radon bwtween the ground and floor 1!!! - C-p!!!! so from this example we could see , when the variable is Directly related to our question or hypothesis, and there are enough information in it and it is experimental manipulations, we choose it as fixed factor, just like the variable “floor” in these example. and if the variable is not our main concern and maybe we don’t have enough information about it but it still have some inluence on the variation of response variable, this would help us to increase our test power,then we set it as radom factor, just like the variable of county in our example!!! when we think about these two types of effect, the model we build would be called linear mixd model!! - C-l1!!!there are also two types of radom effct in the mixed model, let’s see the first one,in R we set the radom effect like this,and the floor is the fixed factor. In front of the vertical line, there is only the number of 1 which means there are the same slope of leverls inside the factor of ramdom , this is called random intercept models . - C-l2!!!!, but in this model In front of the vertical line, there are number of 1 and the fixed factor which means there are differnt slope of leverls inside the factor of ramdom. and this is called random slope models!!i would draw a picture to show their differnce,——-so in conclusion, in the radom intercept models, among the differnt county , the concentration of radon on the ground is diffent, but the differances between the ground and floor 1 are the same , but in this random slope models, among the differnt county , the concentration of radon on the ground is diffent as well as differances between the ground and floor 1 are differnt!!!! - Result!!!!!!: when we summary these two types of mixed moedls ,we could the result there are 2 parts ,one part is about radom effect and it told us about the components of variance, why the infomation is so limiited because when we estimate the radom factor’s parameter, we assume it is consistent with a normal distribution and its mean value is 0!!! another part is about fixed effect , it only shows the estimate and t value, there is no p value?? why?? i would explain later. - Compare,let’s compare these two models’ resutls, (left!!)as you can see the intercpet reprecent floor0, and because of the diffent types of radom models, so their estimates are a little bit differnt, this is the part of fixed effect , as for the part of radom effect, (right!!!)see here, we could see when we use the radom slope models, the std deviance of residual is smaller!!!that means in the unexplained part of the total variation of response variable becomes less!!but the question is no matter in this part or in the fixed effect part we don’ t have enough imformation to decide should I remove some independent variable? or the model i build is good enough?? — class: center, middle # <font color=red>How to evaluate lmm ??? </font></p>
<p>??? in order to answer these questions, i would give the third example, because the in the former one, all of the independent variables are factors, that is not easy to understand. — ## example 3</p>
<div id="htmlwidget-b02f154cbda553c47121" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b02f154cbda553c47121">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103"],[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10],[5,7,9,10,12,13,14,15,18,19,22,23,5,7,9,11,12,13,15,16,19,22,24,1,3,6,10,12,14,15,16,18,19,23,1,3,4,5,7,9,10,12,13,14,19,21,3,5,6,7,9,11,12,14,17,18,19,20,1,6,7,9,11,12,16,17,2,3,6,9,10,14,15,23,3,7,10,11,13,14,19,21,22,5,9,10,15,16,20,22,24,2,3,8,9,12,13,15,18,19,21,23,24],["hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn","hn"],["L","L","L","L","L","L","L","L","L","L","L","L","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","L","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","D","L","L","L","L","L","L","L","L","L","D","D","D","D","D","D","D","D","L","L","L","L","L","L","L","L","L","L","L","L"],[0,0,0,0.25,0.25,0.25,0.1,0.1,0.25,0.1,0.1,0,0.25,0.1,0.1,0.1,0,0,0,0,0.25,0.1,0.25,0.1,0,0.25,0.25,0.1,0.25,0,0,0,0.1,0.1,0.1,0,0.1,0.25,0.25,0,0.1,0.25,0,0,0.25,0.1,0,0.1,0.1,0,0.25,0,0.25,0.25,0.1,0,0.1,0.25,0,0.1,0.1,0,0.25,0.1,0.25,0.25,0,0.25,0.1,0,0,0.25,0.1,0.25,0.1,0.1,0.25,0.25,0,0.25,0,0,0,0.1,0,0,0.1,0.1,0.25,0.25,0.1,0.1,0,0.1,0.1,0.25,0,0,0.25,0.25,0.1,0,0.25],[-0.0752481,3.3149585,8.549523,5.1861251,2.09193,1.4813057,-1.1771277,7.5755527,1.9539824,3.7577667,5.7964055,13.1485255,-1.8169207,2.9504451,-0.8733739,-0.1823842,2.1298488,1.4664364,2.8113515,0.7036389,-2.2096605,-0.0083978,0.9389882,-0.3427075,1.0133993,-1.1332131,-0.8329182,0.8030257,0.6116822,2.8172785,5.076102,1.5626426,-0.540557,0.8220591,4.6574995,14.2741424,7.9709523,0.7491061,-0.0369281,5.9117597,7.4958859,0.5532096,15.012556,7.8182224,1.5943729,10.5090888,14.3483185,8.5055931,9.295789,18.566262,4.8530393,6.5622034,3.3982022,4.8887791,15.5984096,21.926829,5.8863498,0.519636,1.398989,1.6359123,-1.4759372,3.5779123,1.2281263,-1.2824708,1.0757226,-1.2663269,0.6447824,-0.6887108,3.1017049,-1.5238807,1.3153729,0.8369692,-0.9328774,-1.3938869,0.0201358,0.0322183,8.4156686,2.1937061,4.6715457,2.5771156,6.2942698,10.8723428,13.5479259,3.7375259,1.2599094,2.7719127,-0.9164906,2.4719993,-1.3122374,-2.3342197,1.0614228,7.6649424,9.4952698,9.5842657,12.7105057,6.923749,5.9934859,14.0784455,2.2085065,1.3261626,4.8164121,8.9716121,3.9575399],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>shadehouse<\/th>\n      <th>sld.no<\/th>\n      <th>species<\/th>\n      <th>light<\/th>\n      <th>damage<\/th>\n      <th>growth<\/th>\n      <th>survival<\/th>\n      <th>block<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,5,6,7,8]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>??? here is the example 3 , the response variable is the growth of seedings , and the fixed effect are light and damage, the radom effect is shadehouse. now we have 10 shadehouse , in 5 shedehouse we create the enviroment with light, and this L, in ohter 5 shadehouse we create the enviroment without light, and this is D means dark. in each shadehouse, there a lot of seedings, We give them different degrees of damage to the leaves. so we want to konw how the light and damge to effect the growth of seedlings, and we also assume that there are a little bit difference which we can’t control between these 10 shadehouses and that would impact our results. so we set the shadehouse as radom effect. — class: center, middle # <font color=red>Q1: Is the fixed effect important ??? </font> ??? we have to test the fixed effect and radom effect Separately so the first question is about the fixed effect — .panelset[ .panel[.panel-name[Code-model]</p>
<pre class="r"><code>damage &lt;- read.csv(&quot;E:/academic_resources/note-tutorial/data/plantdamage3.csv&quot;)
damage$shadehouse &lt;- as.factor(damage$shadehouse)
damage$light &lt;- as.factor(damage$light)
library(lme4)
mod1&lt;-lmer(growth~light*damage+(1+damage|shadehouse),damage)
summary(mod1)
anova(mod1)
library(lmerTest)
anova(mod1)</code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-summary]</p>
<pre><code>Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: growth ~ light * damage + (1 + damage | shadehouse)
   Data: damage

REML criterion at convergence: 512

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-2.50490 -0.48897 -0.07229  0.57284  2.71867 

Random effects:
 Groups     Name        Variance Std.Dev. Corr 
 shadehouse (Intercept)  5.292   2.300         
            damage      79.497   8.916    -1.00
 Residual                8.652   2.941         
Number of obs: 103, groups:  shadehouse, 10

Fixed effects:
              Estimate Std. Error t value
(Intercept)      1.677      1.227   1.367
lightL           8.238      1.704   4.835
damage          -9.460      5.933  -1.595
lightL:damage  -19.368      8.073  -2.399

Correlation of Fixed Effects:
            (Intr) lightL damage
lightL      -0.720              
damage      -0.868  0.625       
lightL:damg  0.638 -0.875 -0.735</code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-anova1]</p>
<pre class="r"><code>anova(mod1)</code></pre>
<pre><code>Analysis of Variance Table
             npar  Sum Sq Mean Sq F value
light           1 251.887 251.887 29.1137
damage          1 212.090 212.090 24.5138
light:damage    1  49.802  49.802  5.7563</code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-anova2]</p>
<pre class="r"><code>library(lmerTest)
mod1 &lt;-lmer(growth~light*damage+(1+damage|shadehouse),damage)
anova(mod1)</code></pre>
<pre><code>Type III Analysis of Variance Table with Satterthwaite&#39;s method
              Sum Sq Mean Sq NumDF   DenDF F value    Pr(&gt;F)    
light        202.281 202.281     1  8.5552 23.3801 0.0010710 ** 
damage       194.623 194.623     1 10.7116 22.4949 0.0006526 ***
light:damage  49.802  49.802     1 10.7116  5.7563 0.0358397 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>]</p>
<p>.panel[.panel-name[Other-way1]</p>
<pre class="r"><code>#m0 without fixed effect
mod0 &lt;- update(mod1, ~.-light*damage)
library(pbkrtest)
KRmodcomp(mod0, mod1)</code></pre>
<pre><code>large : growth ~ light * damage + (1 + damage | shadehouse)
small : growth ~ (1 + damage | shadehouse)
         stat     ndf     ddf F.scaling   p.value    
Ftest 17.5396  3.0000  8.0424   0.88849 0.0006902 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>]</p>
<p>.panel[.panel-name[Other-way2]</p>
<pre class="r"><code>library(car)
Anova(mod1, test=&#39;F&#39;)</code></pre>
<pre><code>Analysis of Deviance Table (Type II Wald F tests with Kenward-Roger df)

Response: growth
                   F Df Df.res   Pr(&gt;F)    
light        31.9132  1 8.1631 0.000448 ***
damage       24.4688  1 7.9150 0.001162 ** 
light:damage  5.7266  1 8.1163 0.043222 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>] ] ??? 1. we put our all data into the matrix damage and set the variable of shafehouse and light as factors, load the package lme4 because of we need to use the function to build mixed model, so as you can see , this is also radom slope model,that means we assume the differnce between the growth caused by damge would be differnt in differnt shadehouse. and there is interaction between damage and light, so here is multipy not plus.and then we summary this model 2. as you can see, we could not get more information from this 1. so let’s use function of anova to Determine the importance of each fixed effect in the total variation of response variable. here is two differnt anova function, the second one is from the package lmerTest. let’s see what the difference. 3. in the first anova function see, no P value!!the same question just like the summary result! because when wo test mixed model, it could not caculte out the dgree freedom, so it would not provide the p value, but when we load package lMERtest, it could do that! 4. see p values are here, the results told us both fixed effect , light and damge are important even their interaction! in some situation , if their interaction is not significant, then we should rebuild the model, just change the multipy to plus and rerun the code, in some situation ,the damge term is not significant, but their interaction is significant, we could not remove the variable of damage. 5,6 here are other 2 function from differnt package to test the fixed effect, the way1 compares the model we build and another model without the fixed part that means remove these two varibales. the result told us these two modles are totally differnt. the way2 is almost the same as the anova, but p value is a little bit differnt, because they use differnt ways to caculte the dgree freedom, anyway, this method Takes a more conservative approach to calculate, which means we would be easy to make the type two error,but on the other hand ,if we take the anova methond ,we would be easy make the type one error. normally, It is more unacceptable for us to make type one error, especially in some medicine fields , because we can Judge valid as invalid (2),but we can’t Judge invalid as valid(2),that would be dangerous right? 使用另两个包pbkrtest和car来估计固定因子的显著性，可以发现这两个包都是采取更保守的方法来估计，也就是手动计算部分的方法二，把随机效应的参数估计占了8个自由度.），则是将有效判断成无效（弃真）。在一定程度上，第一类错误和第二类错误是一枚硬币的两面。如果我们比较激进，则容易犯第一类错误；如果我们过于保守，第二类错误会主动找上门来。通常来说我们更不能接受的是第一类错误。 — class: center, middle # <font color=red>Q2: Is the random effect important ??? </font> ??? so now is about evaluating the random effect — .panelset[</p>
<p>.panel[.panel-name[Code-Result]</p>
<pre class="r"><code>#mod_lm without random effect
mod_lm &lt;- lm(growth~light*damage, data=damage)
mod1 &lt;-lmer(growth~light*damage+(1+damage|shadehouse),damage)
#ML
anova(mod1, mod_lm)
#REML
anova(mod1, mod_lm,refit=FALSE)
library(lmerTest)
ranova(mod1)
library(MuMIn)
r.squaredGLMM(mod1)
library(MASS)
confint.result &lt;- confint(mod1, method=&#39;boot&#39;, oldNames=F, nsim = 99) 
confint.result
confint.result &lt;- confint(mod1, method=&#39;boot&#39;, oldNames=F, nsim = 2999) 
confint.result</code></pre>
<p>]</p>
<p>.panel[.panel-name[Recall-ML]</p>
<p>.pull-left[ <img src="E:/academic_resources/note-tutorial/data/img/sta-slides1.png"
width="400" />] .pull-right[ ### REML <font size=5>In statistics, the restricted maximum likelihood (REML) approach is a particular form of maximum likelihood estimation that does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function calculated from a transformed set of data. In contrast to the earlier maximum likelihood estimation, REML can produce <strong>unbiased estimates of variance</strong> and covariance parameters</font> <br> ——Wikipedia] ]</p>
<p>.panel[.panel-name[Result-anova1]</p>
<pre><code>refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>Data: damage
Models:
mod_lm: growth ~ light * damage
mod1: growth ~ light * damage + (1 + damage | shadehouse)
       npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)  
mod_lm    5 543.92 557.09 -266.96   533.92                       
mod1      8 539.92 561.00 -261.96   523.92 9.9952  3    0.01861 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-anova2]</p>
<pre><code>Warning in anova.merMod(mod1, mod_lm, refit = FALSE): some models fit with REML
= TRUE, some not</code></pre>
<pre><code>Data: damage
Models:
mod_lm: growth ~ light * damage
mod1: growth ~ light * damage + (1 + damage | shadehouse)
       npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)    
mod_lm    5 543.92 557.09 -266.96   533.92                         
mod1      8 528.03 549.11 -256.02   512.03 21.886  3   6.89e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>]</p>
<p>.panel[.panel-name[Result-ranova]</p>
<pre><code>ANOVA-like table for random-effects: Single term deletions

Model:
growth ~ light + damage + (1 + damage | shadehouse) + light:damage
                                    npar  logLik    AIC   LRT Df Pr(&gt;Chisq)  
&lt;none&gt;                                 8 -256.02 528.03                      
damage in (1 + damage | shadehouse)    6 -259.46 530.91 6.881  2    0.03205 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre><code>           R2m       R2c
[1,] 0.5637659 0.6607733</code></pre>
<p>]</p>
<p>.panel[.panel-name[bootstrap]</p>
<pre><code>                                        2.5 %     97.5 %
sd_(Intercept)|shadehouse           0.1889274  3.4565465
cor_damage.(Intercept)|shadehouse  -1.0000000  0.9999856
sd_damage|shadehouse                0.1758780 16.9396453
sigma                               2.5809007  3.3152943
(Intercept)                        -0.7735472  4.9253604
lightL                              4.1734198 11.3504727
damage                            -23.5393086  2.4195947
lightL:damage                     -35.7928686 -4.0780617</code></pre>
<pre><code>                                        2.5 %    97.5 %
sd_(Intercept)|shadehouse           0.2440476  3.917839
cor_damage.(Intercept)|shadehouse  -1.0000000  0.000000
sd_damage|shadehouse                0.5051693 17.180195
sigma                               2.5025916  3.343642
(Intercept)                        -0.7752716  4.153886
lightL                              4.8514994 11.499758
damage                            -21.0859093  2.625093
lightL:damage                     -35.1951608 -3.911274</code></pre>
<p>] ]</p>
<p>??? 2. when we evalute the radom effect, could we use anova just like what we did in the example 1? the answer is no, because when we use thay way which means we are using the maximum liklihood, in the linear mixed model we should use REML, and this is the biref introduction about REML from weikipedia, I’m not sure of the detailed math behind it. but REML just transform the data here, and use the transformed data to get the unbiased parameter.let’s see the code 1. in order to test the importance of random effect ,we need to built another model without random effect, and then compare them. when we use anova to compare them, 3. there would be Tip Message which told us this function is using the ML method, 1. but actually , in the anova function we can force it to use the REML method,just code change the the refit to FALSE, 4. but there would be Warning message,the ML method was used in linear model, the REML was used in linear mixed model, so actually they can’t be compared 1. so the best way is to use the ranova from package lmertest, 5. see the result, the first term means the linear mixed model , the second term means remove the radom effect from linear mixed model, and it would be just like the linear model we write before, thus using this function , we don’t need to build another simpler model, and the result said the difference between these two model is signifcant , and the model with random effect is better!!because its AIC is smaller!!! we also could use this function from package MUMIN, see the result, r squared m refers to the part explained by fixed effects, r aquared c refers to the part explained by random effects plus fixed effects, so the subtraction of the two is the true part explained by random effects. - and compare the p value we could find the p value in anova1 is too large and in anova2 is too small which means when we use the wrong method we are making the type 1 or 2 error!!!so anova couldn’be used everywhere!!!!!! 1. here is another way to evaluate the radom and fixed effect together, for every estimates it provides confidence interval instead of p value, some reference said the confidence interval is better than p value because Confidence intervals quantify the uncertainty in the conclusion and provide more information than the p-value!! so we use the function confint() to get that, If we want to test whether this predictor i put into the model is significantly different from zero, we can construct a 97.5% confidence interval to test whether this interval contains zero. In the process, we can additionally know how accurate my estimate is. and If the confidence interval is too wide, then we need to collect more data. - by the way ,old Names =F means the result would show us every full namen of predictor, when the oldnames is default, it is equal true which would only show the number 1,2,3, and the method we use to get confidence intervals is bootstrap, it is a sampling method with put-back, ,so the nism means the times of sampling. lets set different nism to compare. 6. see the result , the intercept and slope of radom effect are both significantly different from 0, because their confidence interval not include 0 so we should put them into the model, and the lightL is significantly different from lightD, the intercept means lightD, so we also need to put this variable into our model, and the the CI include 0 , does this mean i should remove it???????NO!!because as we said before when their interaction is significant, both of them shoud’t be removed even they are not signifcnat seperately. - this is the result of sampling 99 times and this is the result of sampling 99 times 2999 times, compare them ,we would find The upper one has a wider confidence interval than the lower one!!! as i said before when the confidence interval is too wide, it is suggesting we need to collect more data. thus when we can’t increase the number of sampling in our experiments, bootstrap is a good way to incease it In a virtual way!!!</p>
<hr />
<p>class: center, middle # Thanks ??? that’ all, and i have to stress Some information is based on my personal understanding, so there would be some mistakes, maybe we could discuss now ,any question or comments???</p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.2.0 (2022-04-22 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.utf8 
[2] LC_CTYPE=Chinese (Simplified)_China.utf8   
[3] LC_MONETARY=Chinese (Simplified)_China.utf8
[4] LC_NUMERIC=C                               
[5] LC_TIME=Chinese (Simplified)_China.utf8    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] MASS_7.3-56     car_3.0-12      carData_3.0-5   pbkrtest_0.5.1 
 [5] lmerTest_3.1-3  ggpubr_0.4.0    lme4_1.1-29     Matrix_1.4-1   
 [9] ggplot2_3.3.5   MuMIn_1.46.0    DT_0.22         workflowr_1.7.0

loaded via a namespace (and not attached):
 [1] httr_1.4.3          tidyr_1.2.0         sass_0.4.1         
 [4] jsonlite_1.8.0      splines_4.2.0       bslib_0.3.1        
 [7] assertthat_0.2.1    getPass_0.2-2       highr_0.9          
[10] stats4_4.2.0        yaml_2.3.5          numDeriv_2016.8-1.1
[13] backports_1.4.1     pillar_1.7.0        lattice_0.20-45    
[16] glue_1.6.2          uuid_1.1-0          digest_0.6.29      
[19] promises_1.2.0.1    ggsignif_0.6.3      minqa_1.2.4        
[22] colorspace_2.0-3    cowplot_1.1.1       htmltools_0.5.2    
[25] httpuv_1.6.5        pkgconfig_2.0.3     broom_0.8.0        
[28] purrr_0.3.4         scales_1.2.0        processx_3.5.3     
[31] whisker_0.4         later_1.3.0         git2r_0.30.1       
[34] tibble_3.1.7        mgcv_1.8-40         generics_0.1.2     
[37] farver_2.1.0        ellipsis_0.3.2      withr_2.5.0        
[40] cli_3.2.0           magrittr_2.0.3      crayon_1.5.1       
[43] evaluate_0.15       ps_1.6.0            fs_1.5.2           
[46] fansi_1.0.3         nlme_3.1-157        rstatix_0.7.0      
[49] tools_4.2.0         lifecycle_1.0.1     stringr_1.4.0      
[52] munsell_0.5.0       callr_3.7.0         compiler_4.2.0     
[55] jquerylib_0.1.4     rlang_1.0.2         grid_4.2.0         
[58] nloptr_2.0.1        rstudioapi_0.13     htmlwidgets_1.5.4  
[61] crosstalk_1.2.0     labeling_0.4.2      rmarkdown_2.14     
[64] boot_1.3-28         xaringanExtra_0.5.5 gtable_0.3.0       
[67] abind_1.4-5         DBI_1.1.2           R6_2.5.1           
[70] knitr_1.39          dplyr_1.0.8         fastmap_1.1.0      
[73] utf8_1.2.2          rprojroot_2.0.3     stringi_1.7.6      
[76] parallel_4.2.0      Rcpp_1.0.8.3        vctrs_0.4.1        
[79] tidyselect_1.1.2    xfun_0.30          </code></pre>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
